{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM RAG Evaluation with MLflow Example Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42084110-295b-493a-9b3e-5d8d29ff78b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Welcome to this comprehensive tutorial on evaluating Retrieval-Augmented Generation (RAG) systems using MLflow. This tutorial is designed to guide you through the intricacies of assessing various RAG systems, focusing on how they can be effectively integrated and evaluated in a real-world context. Whether you are a data scientist, a machine learning engineer, or simply an enthusiast in the field of AI, this tutorial offers valuable insights and practical knowledge.\n",
    "\n",
    "### What You Will Learn:\n",
    "\n",
    "1. **Setting Up the Environment**:\n",
    "   - Learn how to set up your development environment with all the necessary tools and libraries, including MLflow, OpenAI, ChromaDB, LangChain, and more. This section ensures you have everything you need to start working with RAG systems.\n",
    "\n",
    "2. **Understanding RAG Systems**:\n",
    "   - Delve into the concept of Retrieval-Augmented Generation and its significance in modern AI applications. Understand how RAG systems leverage both retrieval and generation capabilities to provide accurate and contextually relevant responses.\n",
    "\n",
    "3. **Securely Managing API Keys with Databricks Secrets**:\n",
    "   - Explore the best practices for securely managing API keys using Databricks Secrets. This part is crucial for ensuring the security and integrity of your application.\n",
    "\n",
    "4. **Deploying and Testing RAG Systems with MLflow**:\n",
    "   - Learn how to create, deploy, and test RAG systems using MLflow. This includes setting up endpoints, deploying models, and querying them to see their responses in action.\n",
    "\n",
    "5. **Evaluating Performance with MLflow**: \n",
    "   - Dive into evaluating the RAG systems using MLflow's evaluation tools. Understand how to use metrics like relevance and latency to assess the performance of your RAG system.\n",
    "\n",
    "6. **Experimenting with Chunking Strategies**:\n",
    "   - Experiment with different text chunking strategies to optimize the performance of RAG systems. Understand how the size of text chunks affects retrieval accuracy and system responsiveness.\n",
    "\n",
    "7. **Creating and Using Evaluation Datasets**:\n",
    "   - Learn how to create and utilize evaluation datasets (Golden Datasets) to effectively assess the performance of your RAG system.\n",
    "\n",
    "8. **Combining Retrieval and Generation for Question Answering**:\n",
    "   - Gain insights into how retrieval and generation components work together in a RAG system to answer questions based on a given context or documentation.\n",
    "\n",
    "\n",
    "By the end of this tutorial, you will have a thorough understanding of how to evaluate and optimize RAG systems using MLflow. You will be equipped with the knowledge to deploy, test, and refine RAG systems, making them suitable for various practical applications. This tutorial is your stepping stone into the world of advanced AI model evaluation and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d87628a6-ef1d-4586-8080-13f538904076",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openaiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/a8/d9/7ec61c010f0d0b0bc57dab8b8dff398f84230d269e8bfa068ad542ff050c/openai-1.82.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.82.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/c2/c9/d394706deb4c660137caf13e33d05a031d734eb99c051142e039d8ceb794/jiter-0.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\python\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\python\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\python\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\python\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.82.1-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.5 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 256.0/720.5 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  716.8/720.5 kB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 720.5/720.5 kB 7.6 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.2/209.2 kB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.10.0 openai-1.82.1\n",
      "Collecting chromadb==0.4.15\n",
      "  Obtaining dependency information for chromadb==0.4.15 from https://files.pythonhosted.org/packages/f1/2a/549be867b5ab45112aacd9d113af788768a015e9e6d0ade831b45c1df877/chromadb-0.4.15-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (1.10.8)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/d2/32/a91850c7aa8a34f61838913155103808fe90da6f1ea4302731b59e9ba6f2/chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (0.115.12)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (0.34.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/51/16/7b6c5844acee2d343d463ee0e3143cd8c7c48a6c0d079a2f7daf0c80b95c/posthog-4.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (4.12.2)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/8d/a4/e276eefb8105e85f44b8e2e057e3524051aa7c4cefbe45532b040c3511e7/pulsar_client-3.7.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pulsar_client-3.7.0-cp311-cp311-win_amd64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/89/a5/1c6c10322201566015183b52ef011dfa932f5dd1b278de8d75c3b948411d/onnxruntime-1.22.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading onnxruntime-1.22.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (1.33.1)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/ba/ec/6047e230bb6d092c304511315b13893b1c9d9260044dd1228c9d48b6ae0e/opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (1.33.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (0.13.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.4.15)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 0.0/67.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 67.3/67.3 kB 1.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (4.65.0)\n",
      "Collecting overrides>=7.3.1 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/a4/ed/1f1afb2e9e7f38a545d628f864d562a5ae64fe6f7a10e28ffb9b185b4e89/importlib_resources-6.5.2-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/ee/3f/cf92e7e62ccb8dbdf977499547dfc27133124d6467d3a7d23775bcecb0f9/grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/a9/cf/45fb5261ece3e6b9817d3d82b2f343a505fd58674a92577923bc500bd1aa/bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for typer>=0.9.0 from https://files.pythonhosted.org/packages/76/42/3efaf858001d2c2913de7f354563e3a3a2f0decae3efe98427125a8f441e/typer-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/08/10/9f8af3e6f569685ce3af7faab51c8dd9d93b9c38eba339ca31c746119447/kubernetes-32.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==0.4.15)\n",
      "  Obtaining dependency information for tenacity>=8.2.3 from https://files.pythonhosted.org/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\python\\lib\\site-packages (from chromadb==0.4.15) (1.24.3)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\python\\lib\\site-packages (from fastapi>=0.95.2->chromadb==0.4.15) (0.46.2)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (6.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.40.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (0.58.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for requests-oauthlib from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for oauthlib>=3.2.2 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\python\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.26.16)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for durationpy>=0.7 from https://files.pythonhosted.org/packages/b0/0d/9feae160378a3553fa9a339b0e9c1a048e147a4127210e286ef18b730f03/durationpy-0.10-py3-none-any.whl.metadata\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.15)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==0.4.15)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in c:\\python\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\python\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (6.31.1)\n",
      "Requirement already satisfied: sympy in c:\\python\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (1.11.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\python\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\python\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (6.0.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for googleapis-common-protos~=1.52 from https://files.pythonhosted.org/packages/86/f1/62a193f0227cf15a920390abe675f386dec35f7ae3ffe6da582d3ade42c7/googleapis_common_protos-1.70.0-py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.33.1 from https://files.pythonhosted.org/packages/09/52/9bcb17e2c29c1194a28e521b9d3f2ced09028934c3c52a8205884c94b2df/opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for opentelemetry-proto==1.33.1 from https://files.pythonhosted.org/packages/c4/29/48609f4c875c2b6c80930073c82dd1cafd36b6782244c01394007b528960/opentelemetry_proto-1.33.1-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.4.15)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/81/7f/73cefb093e1a2a7c3ffd839e6f9fcafb7a427d300c7f8aef9c64405d8ac6/protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in c:\\python\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.15) (0.54b1)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for backoff>=1.10.0 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\python\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.4.15) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests>=2.28->chromadb==0.4.15) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests>=2.28->chromadb==0.4.15) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\python\\lib\\site-packages (from tqdm>=4.65.0->chromadb==0.4.15) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\python\\lib\\site-packages (from typer>=0.9.0->chromadb==0.4.15) (8.0.4)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb==0.4.15)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\python\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.16.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.4.15)\n",
      "  Obtaining dependency information for httptools>=0.6.3 from https://files.pythonhosted.org/packages/d0/46/4d8e7ba9581416de1c425b8264e2cadd201eb709ec1584c381f3e98f51c1/httptools-0.6.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\python\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.15)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/50/ed/7603c4e164225c12c0d4e8700b64bb00e01a6c4eeea372292a3856be33a4/watchfiles-1.0.5-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading watchfiles-1.0.5-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\python\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (15.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\python\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb==0.4.15) (1.14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (4.9.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.15) (3.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (2.15.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\python\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (4.9.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.15) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (1.2.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15)\n",
      "  Obtaining dependency information for pyreadline3 from https://files.pythonhosted.org/packages/5a/dc/491b7661614ab97483abf2056be1deee4dc2490ecbf7bff9ab5cdbac86e1/pyreadline3-3.5.4-py3-none-any.whl.metadata\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.4.8)\n",
      "Downloading chromadb-0.4.15-py3-none-any.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.8 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 204.8/479.8 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  471.0/479.8 kB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 479.8/479.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.6/151.6 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 152.8/152.8 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 9.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.0/4.3 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.3 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.3/4.3 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 13.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.1/4.3 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/2.0 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 20.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.22.0-cp311-cp311-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.7 MB 16.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.7/12.7 MB 18.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.6/12.7 MB 18.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.5/12.7 MB 18.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.5/12.7 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.4/12.7 MB 19.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.4/12.7 MB 19.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.7 MB 19.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.1/12.7 MB 19.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.8/12.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 18.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.1/12.7 MB 17.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.7 MB 17.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.2/12.7 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.9/55.9 kB ? eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-4.2.0-py2.py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.7/96.7 kB ? eta 0:00:00\n",
      "Downloading pulsar_client-3.7.0-cp311-cp311-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/3.7 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.2/3.7 MB 15.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.6/3.7 MB 15.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.3/3.7 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.7 MB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.3/46.3 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 294.5/294.5 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 88.6/88.6 kB ? eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.7/151.7 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 434.8/434.8 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 243.2/243.2 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading watchfiles-1.0.5-cp311-cp311-win_amd64.whl (291 kB)\n",
      "   ---------------------------------------- 0.0/291.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 291.6/291.6 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.2/83.2 kB 4.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=c2a5b1d90144b4a17a51820dcaa45d2e401a14cd5d3b65dc1e23f7ad425f9127\n",
      "  Stored in directory: c:\\users\\steel\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, tenacity, shellingham, pyreadline3, pulsar-client, protobuf, overrides, oauthlib, importlib-resources, httptools, grpcio, chroma-hnswlib, bcrypt, backoff, watchfiles, rich, requests-oauthlib, posthog, opentelemetry-proto, humanfriendly, googleapis-common-protos, typer, opentelemetry-exporter-otlp-proto-common, kubernetes, coloredlogs, onnxruntime, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Python\\\\Lib\\\\site-packages\\\\google\\\\~upb\\\\_message.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.348\n",
      "  Obtaining dependency information for langchain==0.0.348 from https://files.pythonhosted.org/packages/1e/0a/f038058b27e6eff6aa1079f3b572a406ca761012b0e5e7910cf88443f788/langchain-0.0.348-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.348-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python\\lib\\site-packages (from langchain==0.0.348) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python\\lib\\site-packages (from langchain==0.0.348) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python\\lib\\site-packages (from langchain==0.0.348) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.348)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.348)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core<0.1,>=0.0.12 (from langchain==0.0.348)\n",
      "  Obtaining dependency information for langchain-core<0.1,>=0.0.12 from https://files.pythonhosted.org/packages/96/30/1d6b35a757d698da75b24f8db74132b28de9fd964308e0bc8a2fe8d7be49/langchain_core-0.0.13-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.0.13-py3-none-any.whl.metadata (978 bytes)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.348)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.63 from https://files.pythonhosted.org/packages/97/cd/1c618f89d3fcbb375c99a3ea950bffba8a01862cc0f0ab5032dfb95e8d1e/langsmith-0.0.92-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python\\lib\\site-packages (from langchain==0.0.348) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python\\lib\\site-packages (from langchain==0.0.348) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python\\lib\\site-packages (from langchain==0.0.348) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.348)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/d2/3f/8ba87d9e287b9d385a02a7114ddcef61b26f86411e121c9003eb509a1773/tenacity-8.5.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.348) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.348)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/34/75/51952c7b2d3873b44a0028b1bd26a25078c18f92f256608e8d1dc61b39fd/marshmallow-3.26.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.348)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.348) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\python\\lib\\site-packages (from langchain-core<0.1,>=0.0.12->langchain==0.0.348) (4.9.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.1,>=0.0.12->langchain==0.0.348)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.348) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.348) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.348) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests<3,>=2->langchain==0.0.348) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.348) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain==0.0.348) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.348) (1.0.0)\n",
      "Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 8.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/2.0 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.9/2.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_core-0.0.13-py3-none-any.whl (188 kB)\n",
      "   ---------------------------------------- 0.0/188.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 188.2/188.2 kB ? eta 0:00:00\n",
      "Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.5/56.5 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.9/50.9 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, tenacity, packaging, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.1.2\n",
      "    Uninstalling tenacity-9.1.2:\n",
      "      Successfully uninstalled tenacity-9.1.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 langchain-0.0.348 langchain-core-0.0.13 langsmith-0.0.92 marshmallow-3.26.1 packaging-23.2 tenacity-8.5.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "jupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.9.0 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktokenNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/6f/07/c67ad1724b8e14e2b4c8cca04b15da158733ac60136879131db05dda7c30/tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\python\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/893.9 kB 660.6 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 225.3/893.9 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  890.9/893.9 kB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 893.9/893.9 kB 7.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'mlflow[genai]'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-sdk in c:\\python\\lib\\site-packages (0.55.0)\n",
      "Requirement already satisfied: requests<3,>=2.28.1 in c:\\python\\lib\\site-packages (from databricks-sdk) (2.31.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\python\\lib\\site-packages (from databricks-sdk) (2.40.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python\\lib\\site-packages (from google-auth~=2.0->databricks-sdk) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\lib\\site-packages (from google-auth~=2.0->databricks-sdk) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\lib\\site-packages (from google-auth~=2.0->databricks-sdk) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests<3,>=2.28.1->databricks-sdk) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests<3,>=2.28.1->databricks-sdk) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests<3,>=2.28.1->databricks-sdk) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow>=2.8.1\n",
    "%pip install openai\n",
    "%pip install chromadb==0.4.15\n",
    "%pip install langchain==0.0.348\n",
    "%pip install tiktoken\n",
    "%pip install 'mlflow[genai]'\n",
    "%pip install databricks-sdk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe9a743-feca-4de0-80f9-f64267578482",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()  # noqa: F821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "695c9abf-466c-4b34-a901-852a62d9d10f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings.databricks import DatabricksEmbeddings\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.llms import Databricks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import mlflow\n",
    "import mlflow.deployments\n",
    "from mlflow.deployments import set_deployments_target\n",
    "from mlflow.metrics.genai.metric_definitions import relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f8dfd16-c064-4a7e-9e3e-226894275e95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check mlflow version\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899aa208-48aa-404e-b823-f47e410d9490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.18'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check chroma version\n",
    "chromadb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64d5d5eb-8ee7-496a-be8e-fd658c4a4f44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set-up Databricks Workspace Secrets\n",
    "\n",
    "In order to use the secrets that are defined within this notebook, ensure that they are set via following the [guide to Databricks Secrets here](https://docs.databricks.com/en/security/secrets/secrets.html). It is highly recommended to utilize the [Databricks CLI](https://docs.databricks.com/en/dev-tools/cli/index.html) to set secrets within your workspace for a secure experience.\n",
    "\n",
    "In order to safely store and access your API KEY for Azure OpenAI, ensure that you are setting the following when registering your secret:\n",
    "\n",
    "- **KEY_NAME**: The name that you will be setting for your Azure OpenAI Key\n",
    "- **SCOPE_NAME**: The referenced scope that your secret will reside in, within Databricks Secrets\n",
    "- **OPENAI_API_KEY**: Your Azure OpenAI Key\n",
    "\n",
    "As an example, you would set these keys through a terminal as follows:\n",
    "\n",
    "```bash\n",
    "    databricks secrets put-secret \"<SCOPE_NAME>\" \"<KEY_NAME>\" --string-value \"<OPENAI_API_KEY>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Scope and Key Names that you used when registering your API KEY from the Databricks CLI\n",
    "# Do not put your OpenAI API Key in the notebook!\n",
    "SCOPE_NAME = ...\n",
    "KEY_NAME = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19cb7955-5f15-48e9-896c-fcf36cb60782",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=SCOPE_NAME, key=KEY_NAME)  # noqa: F821\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "# Ensure that you set the name of your OPEN_API_BASE value to the name of your OpenAI instance on Azure\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://<NAME_OF_YOUR_INSTANCE>.openai.azure.com/\"  # replace this!\n",
    "os.environ[\"OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4o-mini\"\n",
    "os.environ[\"OPENAI_ENGINE\"] = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96a5c4f9-8bd7-4e07-8caa-a80133d53433",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create and Test Endpoint on MLflow for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5ecf97-c82c-4812-8b5b-05734bc2fded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "endpoint_name = \"<your-endpoint-name>\"  # replace this!\n",
    "client.create_endpoint(\n",
    "    name=endpoint_name,\n",
    "    config={\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": \"test-gpt\",  # Provide a unique identifying name for your deployments endpoint\n",
    "                \"external_model\": {\n",
    "                    \"name\": \"gpt-4o-mini\",\n",
    "                    \"provider\": \"openai\",\n",
    "                    \"task\": \"llm/v1/completions\",\n",
    "                    \"openai_config\": {\n",
    "                        \"openai_api_type\": \"azure\",\n",
    "                        # replace with your own secrets, for reference see https://docs.databricks.com/en/security/secrets/secrets.html\n",
    "                        \"openai_api_key\": \"{{secrets/scope/openai_api_key}}\",\n",
    "                        \"openai_api_base\": \"{{secrets/scope/openai_api_base}}\",\n",
    "                        \"openai_deployment_name\": \"gpt-4o-mini\",\n",
    "                        \"openai_api_version\": \"2023-05-15\",\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e99f3b3-69b3-4a0c-82bb-d39170038b6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    client.predict(\n",
    "        endpoint=endpoint_name,\n",
    "        inputs={\n",
    "            \"prompt\": \"How is Pi calculated? Be very concise.\",\n",
    "            \"max_tokens\": 100,\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "273d1345-95d7-435a-a7b6-a5f3dbb3f073",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create RAG POC with LangChain and log with MLflow\n",
    "\n",
    "Use Langchain and Chroma to create a RAG system that answers questions based on the MLflow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f64bef-116d-48f0-98d7-a18f858a9b64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    [\n",
    "        \"https://mlflow.org/docs/latest/index.html\",\n",
    "        \"https://mlflow.org/docs/latest/tracking/autolog.html\",\n",
    "        \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\",\n",
    "        \"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "CHUNK_SIZE = 1000\n",
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "llm = Databricks(\n",
    "    endpoint_name=\"<your-endpoint-name>\",  # replace this!\n",
    "    extra_params={\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.1,\n",
    "        \"max_tokens\": 500,\n",
    "    },  # parameters used in AI Playground\n",
    ")\n",
    "\n",
    "\n",
    "# create the embedding function using Databricks Foundation Model APIs\n",
    "embedding_function = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
    "docsearch = Chroma.from_documents(texts, embedding_function)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(fetch_k=3),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54d629aa-7920-44d9-b896-a987adc5bffb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the Vector Database and Retrieval using `mlflow.evaluate()`\n",
    "\n",
    "#### Create an eval dataset (Golden Dataset)\n",
    "\n",
    "We can [leveraging the power of an LLM to generate synthetic data for testing](https://mlflow.org/docs/latest/llms/rag/notebooks/question-generation-retrieval-evaluation.html), offering a creative and efficient alternative. To our readers and customers, we emphasize the importance of crafting a dataset that mirrors the expected inputs and outputs of your RAG application. It's a journey worth taking for the incredible insights you'll gain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d59ea8-3586-459e-88e4-c3b774e415a9",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "EVALUATION_DATASET_PATH = \"https://raw.githubusercontent.com/mlflow/mlflow/master/examples/llms/RAG/static_evaluation_dataset.csv\"\n",
    "\n",
    "synthetic_eval_data = pd.read_csv(EVALUATION_DATASET_PATH)\n",
    "\n",
    "# Load the static evaluation dataset from disk and deserialize the source and retrieved doc ids\n",
    "synthetic_eval_data[\"source\"] = synthetic_eval_data[\"source\"].apply(ast.literal_eval)\n",
    "synthetic_eval_data[\"retrieved_doc_ids\"] = synthetic_eval_data[\"retrieved_doc_ids\"].apply(\n",
    "    ast.literal_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78650ad4-0ea3-41a4-9298-47b47b1e112f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(synthetic_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33374a05-1992-4361-9c7b-3b1e1f8169cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluating the Embedding Model with MLflow\n",
    "\n",
    "In this part of the tutorial, we focus on evaluating the embedding model's performance in the context of a retrieval system. The process involves a series of steps to assess how effectively the model can retrieve relevant documents based on given questions.\n",
    "\n",
    "#### Creating Evaluation Data\n",
    "- We start by defining a set of questions and their corresponding source URLs. This `eval_data` DataFrame acts as our evaluation dataset, allowing us to test the model's ability to link questions to the correct source documents.\n",
    "\n",
    "#### The `evaluate_embedding` Function\n",
    "- The `evaluate_embedding` function is designed to assess the performance of a given embedding function.\n",
    "- **Chunking Strategy**: The function begins by splitting a list of documents into chunks using a `CharacterTextSplitter`. The size of these chunks is crucial, as it can influence the retrieval accuracy.\n",
    "- **Retriever Initialization**: We then use `Chroma.from_documents` to create a retriever with the specified embedding function. This retriever is responsible for finding documents relevant to a given query.\n",
    "- **Retrieval Process**: The function defines a `retriever_model_function` that applies the retriever to each question in the evaluation dataset. It retrieves document IDs that the model finds most relevant for each question.\n",
    "\n",
    "#### MLflow Evaluation\n",
    "- With `mlflow.start_run()`, we initiate an evaluation run. `mlflow.evaluate` is then called to evaluate our retriever model function against the evaluation dataset.\n",
    "- We use the default evaluator with specified targets to assess the model's performance.\n",
    "- The results of this evaluation, stored in `eval_results_of_retriever_df_bge`, are displayed, providing insights into the effectiveness of the embedding model in document retrieval.\n",
    "\n",
    "#### Further Evaluation with Metrics\n",
    "- Additionally, we perform a more detailed evaluation using various metrics like precision, recall, and NDCG at different 'k' values. These metrics offer a deeper understanding of the model's retrieval accuracy and ranking effectiveness.\n",
    "\n",
    "This evaluation step is integral to understanding the strengths and weaknesses of our embedding model in a real-world RAG system. By analyzing these results, we can make informed decisions about model adjustments or optimizations to improve overall system performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e2ac2a-40e7-4fb5-8850-95e51013a269",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "        \"source\": [\n",
    "            [\"https://mlflow.org/docs/latest/index.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/tracking/autolog.html\"],\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0be80f-2e00-4d3a-b05f-63c4c4359efe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_embedding(embedding_function):\n",
    "    CHUNK_SIZE = 1000\n",
    "    list_of_documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(list_of_documents)\n",
    "    retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "\n",
    "    def retrieve_doc_ids(question: str) -> list[str]:\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        return [doc.metadata[\"source\"] for doc in docs]\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        return mlflow.evaluate(\n",
    "            model=retriever_model_function,\n",
    "            data=eval_data,\n",
    "            model_type=\"retriever\",\n",
    "            targets=\"source\",\n",
    "            evaluators=\"default\",\n",
    "        )\n",
    "\n",
    "\n",
    "result1 = evaluate_embedding(DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\"))\n",
    "# To validate the results of a different model, comment out the above line and uncomment the below line:\n",
    "# result2 = evaluate_embedding(SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "\n",
    "eval_results_of_retriever_df_bge = result1.tables[\"eval_results_table\"]\n",
    "# To validate the results of a different model, comment out the above line and uncomment the below line:\n",
    "# eval_results_of_retriever_df_MiniLM = result2.tables[\"eval_results_table\"]\n",
    "display(eval_results_of_retriever_df_bge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fecbb62-44ec-4af4-aa5a-7aa79bfa0943",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate different Top K strategy with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a3acd8-170b-4e14-bc51-da977d2b1939",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    evaluate_results = mlflow.evaluate(\n",
    "        data=eval_results_of_retriever_df_bge,\n",
    "        targets=\"source\",\n",
    "        predictions=\"outputs\",\n",
    "        evaluators=\"default\",\n",
    "        extra_metrics=[\n",
    "            mlflow.metrics.precision_at_k(1),\n",
    "            mlflow.metrics.precision_at_k(2),\n",
    "            mlflow.metrics.precision_at_k(3),\n",
    "            mlflow.metrics.recall_at_k(1),\n",
    "            mlflow.metrics.recall_at_k(2),\n",
    "            mlflow.metrics.recall_at_k(3),\n",
    "            mlflow.metrics.ndcg_at_k(1),\n",
    "            mlflow.metrics.ndcg_at_k(2),\n",
    "            mlflow.metrics.ndcg_at_k(3),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "display(evaluate_results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a52bda-1ea7-4f50-abac-e36d78e1b96b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the Chunking Strategy with MLflow\n",
    "\n",
    "In the realm of RAG systems, the strategy for dividing text into chunks plays a pivotal role in both retrieval effectiveness and the overall system performance. Let's delve into why and how we evaluate different chunking strategies:\n",
    "\n",
    "#### Importance of Chunking:\n",
    "- **Influences Retrieval Accuracy**: The way text is chunked can significantly affect the retrieval component of RAG systems. Smaller chunks may lead to more focused and relevant document retrieval, while larger chunks might capture broader context.\n",
    "- **Impacts System's Responsiveness**: The size of text chunks also influences the speed of document retrieval and processing. Smaller chunks can be processed more quickly but may require the system to evaluate more chunks overall.\n",
    "\n",
    "#### Evaluating Different Chunk Sizes:\n",
    "- **Purpose**: By evaluating different chunk sizes, we aim to find an optimal balance between retrieval accuracy and processing efficiency. This involves experimenting with various chunk sizes to see how they impact the system's performance.\n",
    "- **Method**: We create text chunks of different sizes (e.g., 1000 characters, 2000 characters) and then evaluate how each chunking strategy affects the RAG system. Key aspects to observe include the relevance of retrieved documents and the system's latency.\n",
    "\n",
    "In this example below, we're using the default evaluation suite to provide a comprehensive adjudication of the quality of the responses to retrieved document contents to determine what the impact to the quality of the returned references are, allowing us to explore and tune the chunk size in order to arrive at a configuration that best handles our suite of test questions.\n",
    "\n",
    "Note that the embedding model has changed in this next code block. Above, we were using ``DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")``, while now we're evaluating the performance of ``SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c6bff7-d988-4f09-ac10-6c9ea14b9242",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_chunk_size(chunk_size):\n",
    "    list_of_documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(list_of_documents)\n",
    "    embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "\n",
    "    def retrieve_doc_ids(question: str) -> list[str]:\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        return [doc.metadata[\"source\"] for doc in docs]\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        return mlflow.evaluate(\n",
    "            model=retriever_model_function,\n",
    "            data=eval_data,\n",
    "            model_type=\"retriever\",\n",
    "            targets=\"source\",\n",
    "            evaluators=\"default\",\n",
    "        )\n",
    "\n",
    "\n",
    "result1 = evaluate_chunk_size(1000)\n",
    "result2 = evaluate_chunk_size(2000)\n",
    "\n",
    "\n",
    "display(result1.tables[\"eval_results_table\"])\n",
    "display(result2.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd45cf0e-e139-4059-a2bd-6e4fc4d5d36e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the RAG system using `mlflow.evaluate()`\n",
    "\n",
    "In this section, we'll delve into evaluating the Retrieval-Augmented Generation (RAG) systems using `mlflow.evaluate()`. This evaluation is crucial for assessing the effectiveness and efficiency of RAG systems in question-answering contexts. We focus on two key metrics: `relevance_metric` and `latency`.\n",
    "\n",
    "#### Relevance Metric:\n",
    "- **What It Measures**: The `relevance_metric` quantifies how relevant the RAG system's answers are to the input questions. This metric is critical for understanding the accuracy and contextual appropriateness of the system's responses.\n",
    "- **Why It's Important**: In question-answering systems, relevance is paramount. The ability of a RAG system to provide accurate and contextually correct answers determines its utility and effectiveness in real-world applications, such as information retrieval and customer support.\n",
    "- **Tutorial Context**: Within our tutorial, we utilize the `relevance_metric` to evaluate the quality of answers provided by the RAG system. It serves as a quantitative measure of the system's content accuracy, reflecting its capability to generate useful and precise responses.\n",
    "\n",
    "#### Latency:\n",
    "- **What It Measures**: The `latency` metric captures the response time of the RAG system. It measures the duration taken by the system to generate an answer after receiving a query.\n",
    "- **Why It's Important**: Response time is a critical factor in user experience. In interactive systems, lower latency leads to a more efficient and satisfying user experience. High latency, conversely, can be detrimental to user satisfaction.\n",
    "- **Tutorial Context**: In this tutorial, we assess the system's efficiency in terms of response time through the `latency` metric. This evaluation is vital for understanding the system's performance in a production environment, where timely responses are as important as their accuracy.\n",
    "\n",
    "To start with evaluating, we'll create a simple function that runs each input through the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667ec809-2bb5-4170-9937-6804386b41ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model(input_df):\n",
    "    return input_df[\"questions\"].map(qa).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1064306-b7f3-4b3e-825c-4353d808f21d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create an evaluation dataset (Golden Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5481491-e4a9-42ea-8a3f-f527faffd04d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77f56ede-0b2d-449f-868c-e3a561ef28d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate using LLM as a Judge and Basic Metrics\n",
    "\n",
    "In this concluding section of the tutorial, we perform a final evaluation of our RAG system using MLflow's powerful evaluation tools. This evaluation is crucial for assessing the performance and efficiency of the question-answering model.\n",
    "\n",
    "#### Key Steps in the Evaluation:\n",
    "\n",
    "1. **Setting the Deployment Target**:\n",
    "   - The deployment target is set to Databricks, enabling us to retrieve all endpoints in the Databricks Workspace. This is essential for accessing our deployed models.\n",
    "\n",
    "2. **Relevance Metric Setup**:\n",
    "   - We initialize the `relevance` metric using a model hosted on Databricks. This metric assesses how relevant the answers generated by our RAG system are in response to the input questions.\n",
    "\n",
    "3. **Running the Evaluation**:\n",
    "   - An MLflow run is initiated, and `mlflow.evaluate()` is called to evaluate our RAG model against the prepared evaluation dataset.\n",
    "   - The model is evaluated as a \"question-answering\" system using default evaluators.\n",
    "   - Additional metrics, including the `relevance_metric` and `latency`, are specified. These metrics provide insights into the relevance of the answers and the response time of the model.\n",
    "   - The `evaluator_config` maps the input questions and context, ensuring the correct evaluation of the RAG system.\n",
    "\n",
    "4. **Results and Metrics Display**:\n",
    "   - The results of the evaluation, including key metrics, are displayed in a table format, providing a clear and structured view of the model's performance based on relevance and latency.\n",
    "\n",
    "This comprehensive evaluation step is vital for understanding the effectiveness and efficiency of our RAG system. By assessing both the relevance of the answers and the latency of the responses, we gain a holistic view of the model's performance, guiding any further optimization or deployment decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a290ca1c-11c9-4025-9025-70807479f1e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "set_deployments_target(\"databricks\")  # To retrieve all endpoint in your Databricks Workspace\n",
    "\n",
    "relevance_metric = relevance(\n",
    "    model=\"endpoints:/databricks-llama-2-70b-chat\"\n",
    ")  # You can also use any model you have hosted on Databricks, models from the Marketplace or models in the Foundation model API\n",
    "\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.evaluate(\n",
    "        model,\n",
    "        eval_df,\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        predictions=\"result\",\n",
    "        extra_metrics=[relevance_metric, mlflow.metrics.latency()],\n",
    "        evaluator_config={\n",
    "            \"col_mapping\": {\n",
    "                \"inputs\": \"questions\",\n",
    "                \"context\": \"source_documents\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    print(results.metrics)\n",
    "\n",
    "display(results.tables[\"eval_results_table\"])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "f55e4f48-684d-4903-8bd0-06ca638dcea9",
       "elementType": "command",
       "guid": "f9125ba6-77fb-411f-9859-66be60ebd6a5",
       "options": null,
       "position": {
        "height": 12,
        "width": 22,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "5cc44542-d2d1-4b49-9760-7d912cbd5a44",
     "origId": 2038904942228793,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "MLflow for e2e Evaluation Blog",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
