{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e719264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dash import Dash, html, dcc, dash_table\n",
    "import plotly.express as px\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE, MAE, and R².\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "class StockPriceNN(nn.Module):\n",
    "    \"\"\"Feed-forward neural network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(StockPriceNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class StockPriceLSTM(nn.Module):\n",
    "    \"\"\"LSTM network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super(StockPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_pytorch_forecast(data_path, target, selected_features, horizon=1, params=None, use_lstm=False):\n",
    "    \"\"\"Train PyTorch model for h-month-ahead forecasting.\"\"\"\n",
    "    print(\"Test: Entering train_pytorch_forecast\")\n",
    "    if params is None:\n",
    "        params = {'hidden_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(data_path)\n",
    "        logger.info(f\"Loaded data for {target} with shape {df.shape}\")\n",
    "        if target not in df.columns:\n",
    "            logger.error(f\"Target column {target} not found in data.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "        if df[target].isna().any():\n",
    "            logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "            df = df.dropna(subset=[target])\n",
    "            if df.empty:\n",
    "                logger.error(f\"No valid data for {target} after numeric conversion.\")\n",
    "                return None, None, None\n",
    "        logger.info(f\"Target {target} dtype: {df[target].dtype}\")\n",
    "\n",
    "        if len(df) < horizon:\n",
    "            logger.error(f\"Dataset too short ({len(df)} rows) for horizon {horizon}.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target + f'_t{horizon}'] = df[target].shift(-horizon)\n",
    "        df = df.dropna(subset=selected_features + [target + f'_t{horizon}'])\n",
    "        logger.info(f\"Data shape after NaN handling: {df.shape}\")\n",
    "        if df.empty:\n",
    "            logger.error(f\"No valid data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        X = df[selected_features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        y = df[target + f'_t{horizon}']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "        logger.info(f\"Train indices: {X_train.index[:5].tolist()}, Test indices: {X_test.index[:5].tolist()}\")\n",
    "        y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "        y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "        non_nan_train = ~y_train.isna()\n",
    "        non_nan_test = ~y_test.isna()\n",
    "        X_train = X_train[non_nan_train]\n",
    "        y_train = y_train[non_nan_train]\n",
    "        X_test = X_test[non_nan_test]\n",
    "        y_test = y_test[non_nan_test]\n",
    "        logger.info(f\"Train size after NaN filter: {len(X_train)}, Test size after NaN filter: {len(X_test)}\")\n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            logger.error(f\"No valid train/test data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        print(\"Test2: Before scaling\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if use_lstm:\n",
    "            # Reshape for LSTM [samples, timesteps, features]\n",
    "            X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "            X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "        X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "        y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "        y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "        input_size = X.shape[1]\n",
    "        model = StockPriceLSTM(input_size, params['hidden_size']) if use_lstm else StockPriceNN(input_size, params['hidden_size'])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        mlflow.set_experiment(\"stock_price_forecasting\")\n",
    "        with mlflow.start_run(run_name=f\"{target}_horizon{horizon}\"):\n",
    "            mlflow.set_tag(\"ticker\", target.split('_')[0])\n",
    "            mlflow.set_tag(\"horizon\", horizon)\n",
    "            mlflow.set_tag(\"model_type\", \"LSTM\" if use_lstm else \"NN\")\n",
    "            model.train()\n",
    "            for epoch in range(params['epochs']):\n",
    "                for i in range(0, len(X_train_tensor), params['batch_size']):\n",
    "                    batch_X = X_train_tensor[i:i + params['batch_size']]\n",
    "                    batch_y = y_train_tensor[i:i + params['batch_size']]\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    logger.info(f\"Epoch {epoch+1}/{params['epochs']} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_test_tensor).numpy().flatten()\n",
    "            # Bias correction\n",
    "            with torch.no_grad():\n",
    "                y_train_pred = model(X_train_tensor).numpy().flatten()\n",
    "            bias = np.mean(y_train_pred - y_train)\n",
    "            y_pred += bias\n",
    "            metrics = calculate_metrics(y_test, y_pred)\n",
    "            logger.info(f\"Metrics for {target} (horizon {horizon}): {metrics}\")\n",
    "\n",
    "            current_prices = df.loc[y_test.index, target]\n",
    "            logger.info(f\"Current prices shape: {current_prices.shape}, y_test shape: {y_test.shape}\")\n",
    "            price_change = (y_pred - current_prices) / current_prices * 100\n",
    "            signals = np.where(price_change > 5, \"Buy\", np.where(price_change < -5, \"Sell\", \"Hold\"))\n",
    "            backtest_df = pd.DataFrame({\n",
    "                \"Date\": y_test.index,\n",
    "                \"Actual\": y_test,\n",
    "                \"Predicted\": y_pred,\n",
    "                \"Current_Price\": current_prices,\n",
    "                \"Signal\": signals\n",
    "            })\n",
    "            backtest_df.to_csv(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.log_param(\"features\", \", \".join(selected_features))\n",
    "            mlflow.log_artifact(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.pytorch.log_model(model, \"pytorch_model\", input_example=X_train_scaled[:1])\n",
    "            model_uri = f\"runs:/{mlflow.active_run().info.run_id}/pytorch_model\"\n",
    "            registered_model = mlflow.register_model(model_uri, f\"StockPricePyTorch_Horizon{horizon}\")\n",
    "            logger.info(f\"Model registered: {registered_model.name} version {registered_model.version}\")\n",
    "\n",
    "        return model, metrics, backtest_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        logger.error(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def getStockFeatures(ticker=\"AAPL\"):\n",
    "    print(\"Test: Entering getStockFeatures\")\n",
    "    \"\"\"Get top 10 features for a stock using Random Forest.\"\"\"\n",
    "    data_path = Path(f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\")\n",
    "    if not data_path.exists():\n",
    "        logger.error(f\"Data file for {ticker} not found at {data_path}.\")\n",
    "        return []\n",
    "    df = pd.read_parquet(data_path)\n",
    "    target = f\"{ticker}_Close\"\n",
    "    if target not in df.columns:\n",
    "        logger.error(f\"Target column {target} not found in data for {ticker}.\")\n",
    "        return []\n",
    "    df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "    if df[target].isna().any():\n",
    "        logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "        df = df.dropna(subset=[target])\n",
    "    features = [col for col in df.columns if col != target and not col.startswith(target + '_t')]\n",
    "    logger.info(f\"Found {len(features)} features for {ticker}: {features}\")\n",
    "    if not features:\n",
    "        logger.error(f\"No valid features found for {ticker}.\")\n",
    "        return []\n",
    "\n",
    "    df = df.dropna(subset=features + [target])\n",
    "    logger.info(f\"Data shape after NaN handling for {ticker}: {df.shape}\")\n",
    "    if df.empty:\n",
    "        logger.error(f\"No valid data for {ticker} after NaN handling.\")\n",
    "        return []\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    cv_scores = cross_val_score(rf, X_train_scaled, y_train, cv=5, scoring=\"r2\")\n",
    "    logger.info(f\"Cross-validated R-squared for {ticker}: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    importances = rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    return importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "def process_stock(ticker, horizons=[1, 3]):\n",
    "    print(\"Test: Entering process_stock\")\n",
    "    \"\"\"Process a single stock.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting processing for {ticker}\")\n",
    "        top_features = getStockFeatures(ticker)\n",
    "        if not top_features:\n",
    "            logger.error(f\"No features returned for {ticker}.\")\n",
    "            return None\n",
    "        results = []\n",
    "        model_path = f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\"\n",
    "        target_col = f\"{ticker}_Close\"\n",
    "        for horizon in horizons:\n",
    "            logger.info(f\"Training model for {ticker} horizon {horizon}\")\n",
    "            use_lstm = (horizon == 3)  # Use LSTM for 3-month horizon\n",
    "            model, metrics, backtest_df = train_pytorch_forecast(model_path, target_col, top_features, horizon, use_lstm=use_lstm)\n",
    "            if metrics is None:\n",
    "                logger.error(f\"Failed to train model for {ticker} horizon {horizon}\")\n",
    "                continue\n",
    "            results.append({\n",
    "                'ticker': ticker,\n",
    "                'horizon': horizon,\n",
    "                'rmse': metrics['rmse'],\n",
    "                'mae': metrics['mae'],\n",
    "                'r2': metrics['r2'],\n",
    "                'top_features': top_features,\n",
    "                'backtest_df': backtest_df\n",
    "            })\n",
    "        logger.info(f\"Completed processing for {ticker} with {len(results)} results\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_dashboard(results):\n",
    "    \"\"\"Create a Dash dashboard for buy/sell signals.\"\"\"\n",
    "    app = Dash(__name__)\n",
    "    children = [\n",
    "        html.H1(\"Stock Price Prediction Dashboard\"),\n",
    "        html.H2(\"Top Stocks by R²\")\n",
    "    ]\n",
    "    \n",
    "    for result in results:\n",
    "        ticker = result['ticker']\n",
    "        horizon = result['horizon']\n",
    "        backtest_df = result['backtest_df']\n",
    "        fig = px.line(backtest_df, x=\"Date\", y=[\"Actual\", \"Predicted\"], title=f\"{ticker} {horizon}-Month Forecast\")\n",
    "        fig.add_scatter(x=backtest_df[backtest_df[\"Signal\"] == \"Buy\"][\"Date\"],\n",
    "                        y=backtest_df[backtest_df[\"Signal\"] == \"Buy\"][\"Predicted\"],\n",
    "                        mode=\"markers\", name=\"Buy\", marker=dict(symbol=\"triangle-up\", size=10, color=\"green\"))\n",
    "        fig.add_scatter(x=backtest_df[backtest_df[\"Signal\"] == \"Sell\"][\"Date\"],\n",
    "                        y=backtest_df[backtest_df[\"Signal\"] == \"Sell\"][\"Predicted\"],\n",
    "                        mode=\"markers\", name=\"Sell\", marker=dict(symbol=\"triangle-down\", size=10, color=\"red\"))\n",
    "        children.append(html.H3(f\"{ticker} (Horizon: {horizon} months, R²: {result['r2']:.3f})\"))\n",
    "        children.append(dcc.Graph(figure=fig))\n",
    "        children.append(dash_table.DataTable(\n",
    "            data=backtest_df.to_dict('records'),\n",
    "            columns=[{\"name\": i, \"id\": i} for i in backtest_df.columns],\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            page_size=10\n",
    "        ))\n",
    "        children.append(html.Hr())\n",
    "\n",
    "    app.layout = html.Div(children)\n",
    "    app.run(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Test: Main block\")\n",
    "    tickers = pd.read_csv(\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/src/data/equities.csv\")['Symbol'].tolist()\n",
    "    logger.info(f\"Processing {len(tickers)} tickers: {tickers}\")\n",
    "    # Process a single ticker for testing\n",
    "    results = process_stock(\"AAPL\")\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    if results:\n",
    "        # Create dashboard for AAPL\n",
    "        create_dashboard(results)\n",
    "        \n",
    "        # Process all tickers\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_stock)(ticker) for ticker in tickers)  # Limit for demo\n",
    "        results = [r for r in sum([r if r else [] for r in results], []) if r is not None]\n",
    "        results_df = pd.DataFrame(results)\n",
    "        if not results_df.empty:\n",
    "            logger.info(f\"Results DataFrame shape: {results_df.shape}\")\n",
    "            top_10 = results_df.sort_values(by='r2', ascending=False).head(10)\n",
    "            logger.info(f\"Top 10 models by R²:\\n{top_10[['ticker', 'horizon', 'r2', 'rmse', 'mae']]}\")\n",
    "            top_10.to_csv(\"top_10_forecasts_by_r2.csv\", index=False)\n",
    "\n",
    "            with mlflow.start_run(run_name=\"Top_10_Forecasts_Summary\"):\n",
    "                mlflow.log_artifact(\"top_10_forecasts_by_r2.csv\")\n",
    "                for i, row in top_10.iterrows():\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_r2\", row['r2'])\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_rmse\", row['rmse'])\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_mae\", row['mae'])\n",
    "\n",
    "            create_dashboard(results)  # Dashboard for all tickers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
