{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa3336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/src/data/heavy-stocks.csv\"\n",
    "df_symbols = pd.read_csv(csv_path)\n",
    "symbols = df_symbols['Symbol'].dropna().unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898a1076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NVDA',\n",
       " 'MSFT',\n",
       " 'AAPL',\n",
       " 'AMZN',\n",
       " 'GOOG',\n",
       " 'GOOGL',\n",
       " 'META',\n",
       " 'TSLA',\n",
       " 'AVGO',\n",
       " 'BRK.B',\n",
       " 'WMT',\n",
       " 'JPM',\n",
       " 'V',\n",
       " 'LLY',\n",
       " 'MA',\n",
       " 'NFLX',\n",
       " 'ORCL',\n",
       " 'COST',\n",
       " 'XOM',\n",
       " 'PG',\n",
       " 'JNJ',\n",
       " 'HD',\n",
       " 'BAC',\n",
       " 'ABBV',\n",
       " 'KO',\n",
       " 'PLTR',\n",
       " 'PM',\n",
       " 'TMUS',\n",
       " 'UNH',\n",
       " 'GE',\n",
       " 'CRM',\n",
       " 'CSCO',\n",
       " 'IBM',\n",
       " 'WFC',\n",
       " 'CVX',\n",
       " 'ABT',\n",
       " 'MCD',\n",
       " 'LIN',\n",
       " 'NOW',\n",
       " 'INTU',\n",
       " 'AXP',\n",
       " 'MS',\n",
       " 'DIS',\n",
       " 'ISRG',\n",
       " 'ACN',\n",
       " 'T',\n",
       " 'MRK',\n",
       " 'GS',\n",
       " 'AMD',\n",
       " 'VZ',\n",
       " 'PEP',\n",
       " 'RTX',\n",
       " 'BKNG',\n",
       " 'UBER',\n",
       " 'ADBE',\n",
       " 'TXN',\n",
       " 'CAT',\n",
       " 'QCOM',\n",
       " 'PGR',\n",
       " 'SCHW',\n",
       " 'SPGI',\n",
       " 'BA',\n",
       " 'BSX',\n",
       " 'TMO',\n",
       " 'AMGN',\n",
       " 'BLK',\n",
       " 'SYK',\n",
       " 'HON',\n",
       " 'TJX',\n",
       " 'NEE',\n",
       " 'C',\n",
       " 'GILD',\n",
       " 'DE',\n",
       " 'DHR',\n",
       " 'PFE',\n",
       " 'UNP',\n",
       " 'ADP',\n",
       " 'GEV',\n",
       " 'AMAT',\n",
       " 'ETN',\n",
       " 'CMCSA',\n",
       " 'LOW',\n",
       " 'PANW',\n",
       " 'COF',\n",
       " 'CB',\n",
       " 'CRWD',\n",
       " 'VRTX',\n",
       " 'MMC',\n",
       " 'LMT',\n",
       " 'ANET',\n",
       " 'MU',\n",
       " 'KKR',\n",
       " 'LRCX',\n",
       " 'APH',\n",
       " 'COP',\n",
       " 'ADI',\n",
       " 'BX',\n",
       " 'MDT',\n",
       " 'KLAC',\n",
       " 'CME',\n",
       " 'ICE',\n",
       " 'PLD',\n",
       " 'MO',\n",
       " 'WELL',\n",
       " 'AMT',\n",
       " 'SO',\n",
       " 'TT',\n",
       " 'BMY',\n",
       " 'SBUX',\n",
       " 'CEG',\n",
       " 'WM',\n",
       " 'HCA',\n",
       " 'NKE',\n",
       " 'CTAS',\n",
       " 'DUK',\n",
       " 'SHW',\n",
       " 'MCK',\n",
       " 'FI',\n",
       " 'INTC',\n",
       " 'MDLZ',\n",
       " 'AJG',\n",
       " 'DASH',\n",
       " 'EQIX',\n",
       " 'MCO',\n",
       " 'ELV',\n",
       " 'PH',\n",
       " 'CI',\n",
       " 'TDG',\n",
       " 'UPS',\n",
       " 'MMM',\n",
       " 'CDNS',\n",
       " 'ABNB',\n",
       " 'RSG',\n",
       " 'CVS',\n",
       " 'AON',\n",
       " 'FTNT',\n",
       " 'DELL',\n",
       " 'ORLY',\n",
       " 'APO',\n",
       " 'ECL',\n",
       " 'CL',\n",
       " 'ZTS',\n",
       " 'GD',\n",
       " 'WMB',\n",
       " 'MAR',\n",
       " 'ITW',\n",
       " 'SNPS',\n",
       " 'MSI',\n",
       " 'RCL',\n",
       " 'PNC',\n",
       " 'NOC',\n",
       " 'PYPL',\n",
       " 'HWM',\n",
       " 'USB',\n",
       " 'CMG',\n",
       " 'EMR',\n",
       " 'JCI',\n",
       " 'WDAY',\n",
       " 'REGN',\n",
       " 'COIN',\n",
       " 'BK',\n",
       " 'ADSK',\n",
       " 'TRV',\n",
       " 'KMI',\n",
       " 'MNST',\n",
       " 'AZO',\n",
       " 'CARR',\n",
       " 'ROP',\n",
       " 'APD',\n",
       " 'EOG',\n",
       " 'HLT',\n",
       " 'CSX',\n",
       " 'NEM',\n",
       " 'AXON',\n",
       " 'DLR',\n",
       " 'PAYX',\n",
       " 'COR',\n",
       " 'FCX',\n",
       " 'AFL',\n",
       " 'NSC',\n",
       " 'VST',\n",
       " 'AEP',\n",
       " 'CHTR',\n",
       " 'ALL',\n",
       " 'PSA',\n",
       " 'SPG',\n",
       " 'MET',\n",
       " 'FDX',\n",
       " 'GWW',\n",
       " 'TFC',\n",
       " 'SRE',\n",
       " 'O',\n",
       " 'PWR',\n",
       " 'OKE',\n",
       " 'CPRT',\n",
       " 'BDX',\n",
       " 'NXPI',\n",
       " 'PCAR',\n",
       " 'MPC',\n",
       " 'AMP',\n",
       " 'AIG',\n",
       " 'TEL',\n",
       " 'NDAQ',\n",
       " 'CTVA',\n",
       " 'KMB',\n",
       " 'D',\n",
       " 'FAST',\n",
       " 'URI',\n",
       " 'PSX',\n",
       " 'GM',\n",
       " 'ROST',\n",
       " 'LHX',\n",
       " 'KVUE',\n",
       " 'SLB',\n",
       " 'EW',\n",
       " 'KDP',\n",
       " 'CMI',\n",
       " 'KR',\n",
       " 'EXC',\n",
       " 'VRSK',\n",
       " 'MSCI',\n",
       " 'CCI',\n",
       " 'TGT',\n",
       " 'GLW',\n",
       " 'AME',\n",
       " 'IDXX',\n",
       " 'TTWO',\n",
       " 'FIS',\n",
       " 'HES',\n",
       " 'FICO',\n",
       " 'OXY',\n",
       " 'F',\n",
       " 'FANG',\n",
       " 'LULU',\n",
       " 'VLO',\n",
       " 'XEL',\n",
       " 'YUM',\n",
       " 'CTSH',\n",
       " 'PEG',\n",
       " 'GRMN',\n",
       " 'PCG',\n",
       " 'OTIS',\n",
       " 'ED',\n",
       " 'HIG',\n",
       " 'CBRE',\n",
       " 'ETR',\n",
       " 'BKR',\n",
       " 'CAH',\n",
       " 'PRU',\n",
       " 'DHI',\n",
       " 'RMD',\n",
       " 'EA',\n",
       " 'ROK',\n",
       " 'ACGL',\n",
       " 'VMC',\n",
       " 'SYY',\n",
       " 'WAB',\n",
       " 'ODFL',\n",
       " 'TRGP',\n",
       " 'WEC',\n",
       " 'EBAY',\n",
       " 'DXCM',\n",
       " 'IT',\n",
       " 'VICI',\n",
       " 'EQT',\n",
       " 'IR',\n",
       " 'MLM',\n",
       " 'MPWR',\n",
       " 'GEHC',\n",
       " 'A',\n",
       " 'HSY',\n",
       " 'EFX',\n",
       " 'STZ',\n",
       " 'BRO',\n",
       " 'DAL',\n",
       " 'EXR',\n",
       " 'KHC',\n",
       " 'LYV',\n",
       " 'CCL',\n",
       " 'CSGP',\n",
       " 'MCHP',\n",
       " 'WTW',\n",
       " 'XYL',\n",
       " 'NRG',\n",
       " 'RJF',\n",
       " 'GIS',\n",
       " 'MTB',\n",
       " 'ANSS',\n",
       " 'AVB',\n",
       " 'LVS',\n",
       " 'VTR',\n",
       " 'IRM',\n",
       " 'DD',\n",
       " 'K',\n",
       " 'DTE',\n",
       " 'BR',\n",
       " 'CNC',\n",
       " 'WRB',\n",
       " 'LEN',\n",
       " 'STT',\n",
       " 'ROL',\n",
       " 'TPL',\n",
       " 'AWK',\n",
       " 'KEYS',\n",
       " 'EXE',\n",
       " 'HUM',\n",
       " 'EQR',\n",
       " 'TSCO',\n",
       " 'AEE',\n",
       " 'UAL',\n",
       " 'GDDY',\n",
       " 'PPL',\n",
       " 'FITB',\n",
       " 'IP',\n",
       " 'PPG',\n",
       " 'VRSN',\n",
       " 'DRI',\n",
       " 'VLTO',\n",
       " 'NUE',\n",
       " 'SMCI',\n",
       " 'STX',\n",
       " 'EL',\n",
       " 'SBAC',\n",
       " 'DOV',\n",
       " 'TYL',\n",
       " 'WBD',\n",
       " 'ATO',\n",
       " 'FOXA',\n",
       " 'MTD',\n",
       " 'CNP',\n",
       " 'CHD',\n",
       " 'FTV',\n",
       " 'STE',\n",
       " 'IQV',\n",
       " 'FE',\n",
       " 'CDW',\n",
       " 'CBOE',\n",
       " 'HPQ',\n",
       " 'ES',\n",
       " 'HPE',\n",
       " 'CINF',\n",
       " 'TDY',\n",
       " 'CPAY',\n",
       " 'ADM',\n",
       " 'SW',\n",
       " 'PODD',\n",
       " 'HBAN',\n",
       " 'FOX',\n",
       " 'SYF',\n",
       " 'EIX',\n",
       " 'DG',\n",
       " 'HUBB',\n",
       " 'WAT',\n",
       " 'EXPE',\n",
       " 'NTRS',\n",
       " 'TROW',\n",
       " 'CMS',\n",
       " 'AMCR',\n",
       " 'NVR',\n",
       " 'LH',\n",
       " 'NTAP',\n",
       " 'WSM',\n",
       " 'INVH',\n",
       " 'LII',\n",
       " 'PTC',\n",
       " 'DOW',\n",
       " 'DVN',\n",
       " 'TSN',\n",
       " 'PHM',\n",
       " 'IFF',\n",
       " 'MKC',\n",
       " 'RF',\n",
       " 'LUV',\n",
       " 'BIIB',\n",
       " 'DGX',\n",
       " 'LDOS',\n",
       " 'ULTA',\n",
       " 'CTRA',\n",
       " 'WY',\n",
       " 'DLTR',\n",
       " 'L',\n",
       " 'STLD',\n",
       " 'NWS',\n",
       " 'GPN',\n",
       " 'LYB',\n",
       " 'ZBH',\n",
       " 'WDC',\n",
       " 'ERIE',\n",
       " 'NI',\n",
       " 'MAA',\n",
       " 'ON',\n",
       " 'JBL',\n",
       " 'ESS',\n",
       " 'FDS',\n",
       " 'PFG',\n",
       " 'GPC',\n",
       " 'KEY',\n",
       " 'GEN',\n",
       " 'PKG',\n",
       " 'CFG',\n",
       " 'HAL',\n",
       " 'TRMB',\n",
       " 'RL',\n",
       " 'SNA',\n",
       " 'FSLR',\n",
       " 'HRL',\n",
       " 'MOH',\n",
       " 'PNR',\n",
       " 'TPR',\n",
       " 'DPZ',\n",
       " 'FFIV',\n",
       " 'DECK',\n",
       " 'CLX',\n",
       " 'BF.B',\n",
       " 'COO',\n",
       " 'NWSA',\n",
       " 'LNT',\n",
       " 'BAX',\n",
       " 'EXPD',\n",
       " 'EVRG',\n",
       " 'J',\n",
       " 'WST',\n",
       " 'APTV',\n",
       " 'ZBRA',\n",
       " 'BALL',\n",
       " 'EG',\n",
       " 'CF',\n",
       " 'PAYC',\n",
       " 'OMC',\n",
       " 'KIM',\n",
       " 'HOLX',\n",
       " 'AVY',\n",
       " 'BBY',\n",
       " 'JBHT',\n",
       " 'IEX',\n",
       " 'UDR',\n",
       " 'TXT',\n",
       " 'MAS',\n",
       " 'ALGN',\n",
       " 'REG',\n",
       " 'JKHY',\n",
       " 'TER',\n",
       " 'TKO',\n",
       " 'INCY',\n",
       " 'SOLV',\n",
       " 'CPT',\n",
       " 'ALLE',\n",
       " 'UHS',\n",
       " 'ARE',\n",
       " 'DOC',\n",
       " 'JNPR',\n",
       " 'BLDR',\n",
       " 'SJM',\n",
       " 'NDSN',\n",
       " 'BEN',\n",
       " 'MOS',\n",
       " 'CHRW',\n",
       " 'POOL',\n",
       " 'BXP',\n",
       " 'RVTY',\n",
       " 'PNW',\n",
       " 'AKAM',\n",
       " 'CAG',\n",
       " 'HST',\n",
       " 'TAP',\n",
       " 'BG',\n",
       " 'MRNA',\n",
       " 'SWKS',\n",
       " 'LKQ',\n",
       " 'DVA',\n",
       " 'SWK',\n",
       " 'VTRS',\n",
       " 'CPB',\n",
       " 'AIZ',\n",
       " 'GL',\n",
       " 'EPAM',\n",
       " 'WBA',\n",
       " 'WYNN',\n",
       " 'KMX',\n",
       " 'EMN',\n",
       " 'HAS',\n",
       " 'DAY',\n",
       " 'AOS',\n",
       " 'HSIC',\n",
       " 'IPG',\n",
       " 'HII',\n",
       " 'MGM',\n",
       " 'FRT',\n",
       " 'PARA',\n",
       " 'MKTX',\n",
       " 'NCLH',\n",
       " 'TECH',\n",
       " 'LW',\n",
       " 'MTCH',\n",
       " 'GNRC',\n",
       " 'AES',\n",
       " 'ALB',\n",
       " 'CRL',\n",
       " 'IVZ',\n",
       " 'MHK',\n",
       " 'APA',\n",
       " 'CZR',\n",
       " 'ENPH']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e5873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 13:24:50,932 - INFO - Fetching data for MSFT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 503 symbols:\n",
      "['NVDA', 'MSFT', 'AAPL', 'AMZN', 'GOOG']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We have detected your API key as 9HKRTHJGP77FGDQO and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mget_monthly_adjusted(symbol\u001b[38;5;241m=\u001b[39mticker)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data returned for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\alpha_vantage\\alphavantage.py:218\u001b[0m, in \u001b[0;36mAlphaVantage._output_format.<locals>._format_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 218\u001b[0m     call_response, data_key, meta_data_key \u001b[38;5;241m=\u001b[39m func(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_format\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_format\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\alpha_vantage\\alphavantage.py:160\u001b[0m, in \u001b[0;36mAlphaVantage._call_api_on_func.<locals>._call_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(url, apikey_parameter)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_api_call(url), data_key, meta_data_key\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\alpha_vantage\\alphavantage.py:361\u001b[0m, in \u001b[0;36mAlphaVantage._handle_api_call\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(json_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError Message\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreat_info_as_error:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(json_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreat_info_as_error:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(json_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: We have detected your API key as 9HKRTHJGP77FGDQO and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits."
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Import required libraries\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# ðŸ”§ Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "API_KEY = \"9HKRTHJGP77FGDQO\"  # Replace with your own key if needed\n",
    "OUTPUT_DIR = Path(\"av_monthly\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_path = \"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/src/data/heavy-stocks.csv\"\n",
    "df_symbols = pd.read_csv(csv_path)\n",
    "symbols = df_symbols['Symbol'].dropna().unique().tolist()\n",
    "\n",
    "print(f\"Found {len(symbols)} symbols:\")\n",
    "print(symbols[:5])  # Show a preview\n",
    "\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "ticker=\"MSFT\"\n",
    "logger.info(f\"Fetching data for {ticker}\")\n",
    "data, _ = ts.get_monthly_adjusted(symbol=ticker)\n",
    "\n",
    "if data.empty:\n",
    "    raise ValueError(f\"No data returned for {ticker}\")\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "data.rename(columns={\n",
    "    'date': 'Date',\n",
    "    '1. open': 'Open',\n",
    "    '2. high': 'High',\n",
    "    '3. low': 'Low',\n",
    "    '4. close': 'Close',\n",
    "    '5. adjusted close': 'Adj Close',\n",
    "    '6. volume': 'Volume'\n",
    "}, inplace=True)\n",
    "\n",
    "data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "data['Date'] = pd.to_datetime(data['Date']).dt.strftime('%Y-%m-%d')\n",
    "data = data.sort_values('Date')\n",
    "data = data.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33e03c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polygon-api-client in c:\\python\\lib\\site-packages (1.14.5)\n",
      "Requirement already satisfied: certifi<2026.0.0,>=2022.5.18 in c:\\python\\lib\\site-packages (from polygon-api-client) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.9 in c:\\python\\lib\\site-packages (from polygon-api-client) (1.26.16)\n",
      "Requirement already satisfied: websockets<15.0,>=10.3 in c:\\python\\lib\\site-packages (from polygon-api-client) (10.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install polygon-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2b7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python\\python.exe\n",
      "C:\\Users\\Steel\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n",
      "C:\\msys64\\ucrt64\\bin\\python.exe\n",
      "C:\\Panda3D-1.10.15-x64\\python\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109e4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 13:56:41,483 - INFO - Fetching monthly data for AAPL\n",
      "2025-05-29 13:56:41,885 - INFO - Saved AAPL to polygon_monthly/AAPL_monthly.csv\n",
      "2025-05-29 13:56:42,886 - INFO - Fetching monthly data for MSFT\n",
      "2025-05-29 13:56:42,946 - INFO - Saved MSFT to polygon_monthly/MSFT_monthly.csv\n",
      "2025-05-29 13:56:43,947 - INFO - Fetching monthly data for GOOG\n",
      "2025-05-29 13:56:44,688 - ERROR - Failed to fetch GOOG: HTTPSConnectionPool(host='api.polygon.io', port=443): Max retries exceeded with url: /v2/aggs/ticker/GOOG/range/1/month/2000-01-01/2025-05-29?limit=5000 (Caused by ResponseError('too many 429 error responses'))\n"
     ]
    }
   ],
   "source": [
    "# Polygon.io setup\n",
    "from polygon import RESTClient\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Replace with your Polygon API Key\n",
    "POLYGON_API_KEY = \"V14jfLkPqCx651gIIRS0ipNy5m8BH0xS\"\n",
    "client = RESTClient(POLYGON_API_KEY)\n",
    "\n",
    "# Tickers to fetch\n",
    "tickers = ['AAPL', 'MSFT', 'GOOG']\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"polygon_monthly\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Fetch and save monthly data\n",
    "for ticker in tickers:\n",
    "    logging.info(f\"Fetching monthly data for {ticker}\")\n",
    "    try:\n",
    "        bars = client.get_aggs(\n",
    "            ticker=ticker,\n",
    "            multiplier=1,\n",
    "            timespan=\"month\",\n",
    "            from_=\"2000-01-01\",\n",
    "            to=\"2025-05-29\",\n",
    "            limit=5000\n",
    "        )\n",
    "        df = pd.DataFrame([bar.__dict__ for bar in bars])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df = df[['timestamp', 'close']]\n",
    "        df = df.round(4)\n",
    "        df.sort_values('timestamp', inplace=True)\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "        df.set_index('date',inplace=True)\n",
    "        df.to_csv(output_dir / f\"{ticker}_monthly.csv\", index=True)\n",
    "        logging.info(f\"Saved {ticker} to {output_dir}/{ticker}_monthly.csv\")\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to fetch {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a531cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bars = client.get_aggs(\n",
    "    ticker=ticker,\n",
    "    multiplier=1,\n",
    "    timespan=\"month\",\n",
    "    from_=\"2000-01-01\",\n",
    "    to=\"2025-05-29\",\n",
    "    limit=5000\n",
    ")\n",
    "df = pd.DataFrame([bar.__dict__ for bar in bars])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df = df[['timestamp', 'close']]\n",
    "df = df.round(4)\n",
    "df.sort_values('timestamp', inplace=True)\n",
    "df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "df.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf17a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cdce28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d1bc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AAPL...\n",
      "Success! Saved data to AAPL_monthly_yf.csv\n",
      "                            Close\n",
      "Date                             \n",
      "2000-01-01 00:00:00-05:00  0.7795\n",
      "2000-02-01 00:00:00-05:00  0.8612\n",
      "2000-03-01 00:00:00-05:00  1.0204\n",
      "2000-04-01 00:00:00-05:00  0.9321\n",
      "2000-05-01 00:00:00-04:00  0.6311\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "try:\n",
    "    print(f\"Testing {ticker}...\")\n",
    "    stock = yf.Ticker(ticker)\n",
    "    df = stock.history(start=\"2000-01-01\", end=\"2025-05-29\", interval=\"1mo\")\n",
    "    if not df.empty:\n",
    "        df = df[['Close']].round(4)\n",
    "        df.to_csv(f\"{ticker}_monthly_yf.csv\")\n",
    "        print(f\"Success! Saved data to {ticker}_monthly_yf.csv\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"No data for {ticker}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "193f64b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b22ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-01 04:00:00</th>\n",
       "      <td>123.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 04:00:00</th>\n",
       "      <td>120.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01 04:00:00</th>\n",
       "      <td>133.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 04:00:00</th>\n",
       "      <td>137.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01 04:00:00</th>\n",
       "      <td>131.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01 04:00:00</th>\n",
       "      <td>125.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01 04:00:00</th>\n",
       "      <td>133.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01 05:00:00</th>\n",
       "      <td>140.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 05:00:00</th>\n",
       "      <td>141.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01 05:00:00</th>\n",
       "      <td>139.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01 05:00:00</th>\n",
       "      <td>152.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01 04:00:00</th>\n",
       "      <td>164.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 04:00:00</th>\n",
       "      <td>173.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01 04:00:00</th>\n",
       "      <td>183.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01 04:00:00</th>\n",
       "      <td>173.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:00:00</th>\n",
       "      <td>165.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01 04:00:00</th>\n",
       "      <td>167.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 04:00:00</th>\n",
       "      <td>172.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01 04:00:00</th>\n",
       "      <td>170.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01 05:00:00</th>\n",
       "      <td>190.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 05:00:00</th>\n",
       "      <td>205.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01 05:00:00</th>\n",
       "      <td>172.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01 05:00:00</th>\n",
       "      <td>156.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01 04:00:00</th>\n",
       "      <td>160.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-01 04:00:00</th>\n",
       "      <td>172.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      close\n",
       "date                       \n",
       "2023-05-01 04:00:00  123.37\n",
       "2023-06-01 04:00:00  120.97\n",
       "2023-07-01 04:00:00  133.11\n",
       "2023-08-01 04:00:00  137.35\n",
       "2023-09-01 04:00:00  131.85\n",
       "2023-10-01 04:00:00  125.30\n",
       "2023-11-01 04:00:00  133.92\n",
       "2023-12-01 05:00:00  140.93\n",
       "2024-01-01 05:00:00  141.80\n",
       "2024-02-01 05:00:00  139.78\n",
       "2024-03-01 05:00:00  152.26\n",
       "2024-04-01 04:00:00  164.64\n",
       "2024-05-01 04:00:00  173.96\n",
       "2024-06-01 04:00:00  183.42\n",
       "2024-07-01 04:00:00  173.15\n",
       "2024-08-01 04:00:00  165.11\n",
       "2024-09-01 04:00:00  167.19\n",
       "2024-10-01 04:00:00  172.69\n",
       "2024-11-01 04:00:00  170.49\n",
       "2024-12-01 05:00:00  190.44\n",
       "2025-01-01 05:00:00  205.60\n",
       "2025-02-01 05:00:00  172.22\n",
       "2025-03-01 05:00:00  156.23\n",
       "2025-04-01 04:00:00  160.89\n",
       "2025-05-01 04:00:00  172.50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "V14jfLkPqCx651gIIRS0ipNy5m8BH0xS\n",
    "\n",
    "d0s9i2hr01qkkpltrpe0d0s9i2hr01qkkpltrpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe02cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting finnhub-python\n",
      "  Obtaining dependency information for finnhub-python from https://files.pythonhosted.org/packages/17/09/9240b2a222717e7bda81f954047b662f2744aaeb6b29d62e89bb5c49dd16/finnhub_python-2.4.23-py3-none-any.whl.metadata\n",
      "  Downloading finnhub_python-2.4.23-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\python\\lib\\site-packages (from finnhub-python) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (2023.7.22)\n",
      "Downloading finnhub_python-2.4.23-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: finnhub-python\n",
      "Successfully installed finnhub-python-2.4.23\n"
     ]
    }
   ],
   "source": [
    "!pip install finnhub-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c6c9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finnhub.io setup\n",
    "import finnhub\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Replace with your Finnhub API Key\n",
    "FINNHUB_API_KEY = \"d0s9ll9r01qkkpltsgigd0s9ll9r01qkkpltsgj0\"\n",
    "finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bf270cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<finnhub.client.Client at 0x1ea7aee2850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finnhub_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a9fbf10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FinnhubAPIException",
     "evalue": "FinnhubAPIException(status_code: 403): You don't have access to this resource.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFinnhubAPIException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m finnhub_client\u001b[38;5;241m.\u001b[39mstock_candles(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1590988249\u001b[39m, \u001b[38;5;241m1591852249\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\finnhub\\client.py:226\u001b[0m, in \u001b[0;36mClient.stock_candles\u001b[1;34m(self, symbol, resolution, _from, to, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstock_candles\u001b[39m(\u001b[38;5;28mself\u001b[39m, symbol, resolution, _from, to, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    219\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_two_dicts({\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: symbol,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolution\u001b[39m\u001b[38;5;124m\"\u001b[39m: resolution,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m: _from,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m: to\n\u001b[0;32m    224\u001b[0m     }, kwargs)\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/stock/candle\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\finnhub\\client.py:71\u001b[0m, in \u001b[0;36mClient._get\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\finnhub\\client.py:41\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_params(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m     40\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session, method)(uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\finnhub\\client.py:46\u001b[0m, in \u001b[0;36mClient._handle_response\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_response\u001b[39m(response):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FinnhubAPIException(response)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         content_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFinnhubAPIException\u001b[0m: FinnhubAPIException(status_code: 403): You don't have access to this resource."
     ]
    }
   ],
   "source": [
    "res = finnhub_client.stock_candles('AAPL', 'D', 1590988249, 1591852249)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e97e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 13:59:07,359 - INFO - Fetching monthly data for AAPL\n",
      "2025-05-29 13:59:07,825 - ERROR - Failed to fetch AAPL: FinnhubAPIException(status_code: 401): Invalid API key\n",
      "2025-05-29 13:59:07,826 - INFO - Fetching monthly data for MSFT\n",
      "2025-05-29 13:59:07,864 - ERROR - Failed to fetch MSFT: FinnhubAPIException(status_code: 401): Invalid API key\n",
      "2025-05-29 13:59:07,864 - INFO - Fetching monthly data for GOOG\n",
      "2025-05-29 13:59:07,904 - ERROR - Failed to fetch GOOG: FinnhubAPIException(status_code: 401): Invalid API key\n"
     ]
    }
   ],
   "source": [
    "# Finnhub.io setup\n",
    "import finnhub\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Replace with your Finnhub API Key\n",
    "FINNHUB_API_KEY = \"d0s9i2hr01qkkpltrpe0d0s9i2hr01qkkpltrpeg\"\n",
    "finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)\n",
    "\n",
    "# Tickers to fetch\n",
    "tickers = ['AAPL', 'MSFT', 'GOOG']\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"finnhub_monthly\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_month_start_end_dates(year: int, month: int):\n",
    "    first_day = datetime(year, month, 1)\n",
    "    last_day = datetime(year, month, calendar.monthrange(year, month)[1])\n",
    "    return int(first_day.timestamp()), int(last_day.timestamp())\n",
    "\n",
    "# Fetch and save monthly data\n",
    "for ticker in tickers:\n",
    "    logging.info(f\"Fetching monthly data for {ticker}\")\n",
    "    try:\n",
    "        all_months = []\n",
    "        for year in range(2015, 2025):\n",
    "            for month in range(1, 13):\n",
    "                start, end = get_month_start_end_dates(year, month)\n",
    "                candles = finnhub_client.stock_candles(ticker, 'D', start, end)\n",
    "                if candles.get('s') != 'ok':\n",
    "                    continue\n",
    "                df = pd.DataFrame(candles)\n",
    "                df['t'] = pd.to_datetime(df['t'], unit='s')\n",
    "                monthly_df = df.groupby(df['t'].dt.to_period('M')).agg({\n",
    "                    'o': 'first',\n",
    "                    'h': 'max',\n",
    "                    'l': 'min',\n",
    "                    'c': 'last',\n",
    "                    'v': 'sum'\n",
    "                }).reset_index()\n",
    "                all_months.append(monthly_df)\n",
    "\n",
    "        if all_months:\n",
    "            final_df = pd.concat(all_months)\n",
    "            final_df.rename(columns={\n",
    "                't': 'Date',\n",
    "                'o': 'Open',\n",
    "                'h': 'High',\n",
    "                'l': 'Low',\n",
    "                'c': 'Close',\n",
    "                'v': 'Volume'\n",
    "            }, inplace=True)\n",
    "            final_df['Date'] = final_df['Date'].astype(str)\n",
    "            final_df = final_df.round(4)\n",
    "            final_df.to_csv(output_dir / f\"{ticker}_monthly.csv\", index=False)\n",
    "            logging.info(f\"Saved {ticker} to {output_dir}/{ticker}_monthly.csv\")\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to fetch {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df060a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygon import RESTClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa11bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polygon-api-client\n",
      "  Obtaining dependency information for polygon-api-client from https://files.pythonhosted.org/packages/fb/16/ee8a361c40432408684113e90fba6fe6a862ffd8a7c518be1167479e8cad/polygon_api_client-1.14.5-py3-none-any.whl.metadata\n",
      "  Using cached polygon_api_client-1.14.5-py3-none-any.whl.metadata (952 bytes)\n",
      "Requirement already satisfied: certifi<2026.0.0,>=2022.5.18 in c:\\python\\lib\\site-packages (from polygon-api-client) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.9 in c:\\python\\lib\\site-packages (from polygon-api-client) (1.26.16)\n",
      "Requirement already satisfied: websockets<15.0,>=10.3 in c:\\python\\lib\\site-packages (from polygon-api-client) (10.4)\n",
      "Using cached polygon_api_client-1.14.5-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: polygon-api-client\n",
      "Successfully installed polygon-api-client-1.14.5\n"
     ]
    }
   ],
   "source": [
    "!pip install polygon-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb49c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\python\\lib\\site-packages (0.2.33)\n",
      "Collecting yfinance\n",
      "  Obtaining dependency information for yfinance from https://files.pythonhosted.org/packages/73/b5/d50eec88bc731bb8570ae42a9b764a36144e217361c33fa068391ff59ba3/yfinance-0.2.61-py2.py3-none-any.whl.metadata\n",
      "  Downloading yfinance-0.2.61-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\python\\lib\\site-packages (from yfinance) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\python\\lib\\site-packages (from yfinance) (1.24.3)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\python\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\python\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\python\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\python\\lib\\site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\python\\lib\\site-packages (from yfinance) (2.3.10)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\python\\lib\\site-packages (from yfinance) (3.17.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\python\\lib\\site-packages (from yfinance) (4.12.2)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Obtaining dependency information for curl_cffi>=0.7 from https://files.pythonhosted.org/packages/d9/f2/a46509f4f3054bbbaae822c74145bc7377ef3ca3b12c3f2bb82314d81b2a/curl_cffi-0.11.1-cp39-abi3-win_amd64.whl.metadata\n",
      "  Downloading curl_cffi-0.11.1-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Obtaining dependency information for protobuf>=3.19.0 from https://files.pythonhosted.org/packages/44/3a/b15c4347dd4bf3a1b0ee882f384623e2063bb5cf9fa9d57990a4f7df2fb6/protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Obtaining dependency information for websockets>=13.0 from https://files.pythonhosted.org/packages/98/93/e36c73f78400a65f5e236cd376713c34182e6663f6889cd45a4a04d8f203/websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\python\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.15.1)\n",
      "Collecting certifi>=2024.2.2 (from curl_cffi>=0.7->yfinance)\n",
      "  Obtaining dependency information for certifi>=2024.2.2 from https://files.pythonhosted.org/packages/4a/7e/3db2bd1b1f9e95f7cddca6d6e75e2f2bd9f51b1246e546d88addca0106bd/certifi-2025.4.26-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests>=2.31->yfinance) (1.26.16)\n",
      "Requirement already satisfied: pycparser in c:\\python\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.61-py2.py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 117.9/117.9 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading curl_cffi-0.11.1-cp39-abi3-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.7/1.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 18.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 15.0 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "   ---------------------------------------- 0.0/435.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 435.3/435.3 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 176.8/176.8 kB ? eta 0:00:00\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 159.6/159.6 kB ? eta 0:00:00\n",
      "Installing collected packages: websockets, protobuf, certifi, curl_cffi, yfinance\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 10.4\n",
      "    Uninstalling websockets-10.4:\n",
      "      Successfully uninstalled websockets-10.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Python\\\\Lib\\\\site-packages\\\\~ebsockets\\\\speedups.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1638924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3 tickers: ['AAPL', 'MSFT', 'GOOG']\n",
      "Fetching data for AAPL...\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 14:04:09,768 - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-29 14:04:09,769 - ERROR - ['AAPL']: Exception('%ticker%: No price data found, symbol may be delisted (1mo 2020-05-30 -> 2025-05-29)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No data found for AAPL\n",
      "Fetching data for MSFT...\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 14:04:11,836 - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-29 14:04:11,836 - ERROR - ['MSFT']: Exception('%ticker%: No price data found, symbol may be delisted (1mo 2020-05-30 -> 2025-05-29)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No data found for MSFT\n",
      "Fetching data for GOOG...\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 14:04:13,925 - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-29 14:04:13,926 - ERROR - ['GOOG']: Exception('%ticker%: No price data found, symbol may be delisted (1mo 2020-05-30 -> 2025-05-29)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No data found for GOOG\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Function to get S&P 500 tickers (optional, for scaling to all S&P 500 stocks)\n",
    "def get_sp500_tickers():\n",
    "    try:\n",
    "        url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "        tables = pd.read_html(url)\n",
    "        sp500_table = tables[0]\n",
    "        tickers = sp500_table['Symbol'].tolist()\n",
    "        # Replace problematic tickers (e.g., BRK.B to BRK-B)\n",
    "        return [ticker.replace('.', '-') for ticker in tickers]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching S&P 500 tickers: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to fetch historical data\n",
    "def fetch_historical_data(tickers, start_date, end_date, interval='1mo'):\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            print(f\"Fetching data for {ticker}...\")\n",
    "            # Use yf.download for consistency with your original script\n",
    "            df = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "            if not df.empty:\n",
    "                # Keep only adjusted close prices and round to 4 decimal places\n",
    "                df = df[['Adj Close']].rename(columns={'Adj Close': ticker}).round(4)\n",
    "                # Save to CSV\n",
    "                df.to_csv(f\"{ticker}_monthly_yf.csv\")\n",
    "                print(f\"Saved data for {ticker} to {ticker}_monthly_yf.csv\")\n",
    "            else:\n",
    "                print(f\"No data found for {ticker}\")\n",
    "            # Avoid rate-limiting\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Define date range (5 years ago to today, avoiding future dates)\n",
    "    end_date = datetime.now().date()\n",
    "    start_date = end_date - timedelta(days=5*365)  # 5 years ago\n",
    "\n",
    "    # Use your test tickers or fetch all S&P 500 tickers\n",
    "    tickers = ['AAPL', 'MSFT', 'GOOG']  # Replace with get_sp500_tickers() for all S&P 500\n",
    "    # tickers = get_sp500_tickers()\n",
    "\n",
    "    if not tickers:\n",
    "        print(\"No tickers to process. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Processing {len(tickers)} tickers: {tickers[:5]}{'...' if len(tickers) > 5 else ''}\")\n",
    "\n",
    "    # Fetch historical data\n",
    "    fetch_historical_data(tickers, start_date, end_date, interval='1mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68cb098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 14:05:15,412 - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-29 14:05:15,413 - ERROR - ['AAPL']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2020-05-01 -> 2025-05-29)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No data found for AAPL\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Test a single ticker\n",
    "ticker = \"AAPL\"\n",
    "start_date = \"2020-05-01\"\n",
    "end_date = \"2025-05-29\"\n",
    "\n",
    "try:\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\", auto_adjust=True)\n",
    "    if not df.empty:\n",
    "        df = df[['Close']].round(4)\n",
    "        df.to_csv(f\"{ticker}_monthly_yf.csv\")\n",
    "        print(f\"Data saved to {ticker}_monthly_yf.csv\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"No data found for {ticker}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da35ee77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='chart.finance.yahoo.com', port=80): Max retries exceeded with url: /table.csv?s=MSFT&a=2&b=15&c=2015&d=4&e=15&f=2017&g=d&ignore=.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000204E47B6D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mC:\\Python\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connectionpool.py:415\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28msuper\u001b[39m(HTTPConnection, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\http\\client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\http\\client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\http\\client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\http\\client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m \n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\Lib\\http\\client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x00000204E47B6D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='chart.finance.yahoo.com', port=80): Max retries exceeded with url: /table.csv?s=MSFT&a=2&b=15&c=2015&d=4&e=15&f=2017&g=d&ignore=.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000204E47B6D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://chart.finance.yahoo.com/table.csv?s=MSFT&a=2&b=15&c=2015&d=4&e=15&f=2017&g=d&ignore=.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='chart.finance.yahoo.com', port=80): Max retries exceeded with url: /table.csv?s=MSFT&a=2&b=15&c=2015&d=4&e=15&f=2017&g=d&ignore=.csv (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000204E47B6D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "data = requests.get(\"http://chart.finance.yahoo.com/table.csv?s=MSFT&a=2&b=15&c=2015&d=4&e=15&f=2017&g=d&ignore=.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8959421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\python\\lib\\site-packages (0.2.33)\n",
      "Collecting yfinance\n",
      "  Obtaining dependency information for yfinance from https://files.pythonhosted.org/packages/73/b5/d50eec88bc731bb8570ae42a9b764a36144e217361c33fa068391ff59ba3/yfinance-0.2.61-py2.py3-none-any.whl.metadata\n",
      "  Using cached yfinance-0.2.61-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\python\\lib\\site-packages (from yfinance) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\python\\lib\\site-packages (from yfinance) (1.24.3)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\python\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\python\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\python\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\python\\lib\\site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\python\\lib\\site-packages (from yfinance) (2.3.10)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\python\\lib\\site-packages (from yfinance) (3.17.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\python\\lib\\site-packages (from yfinance) (4.12.2)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Obtaining dependency information for curl_cffi>=0.7 from https://files.pythonhosted.org/packages/d9/f2/a46509f4f3054bbbaae822c74145bc7377ef3ca3b12c3f2bb82314d81b2a/curl_cffi-0.11.1-cp39-abi3-win_amd64.whl.metadata\n",
      "  Using cached curl_cffi-0.11.1-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Obtaining dependency information for protobuf>=3.19.0 from https://files.pythonhosted.org/packages/44/3a/b15c4347dd4bf3a1b0ee882f384623e2063bb5cf9fa9d57990a4f7df2fb6/protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata\n",
      "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\python\\lib\\site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\python\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.15.1)\n",
      "Collecting certifi>=2024.2.2 (from curl_cffi>=0.7->yfinance)\n",
      "  Obtaining dependency information for certifi>=2024.2.2 from https://files.pythonhosted.org/packages/4a/7e/3db2bd1b1f9e95f7cddca6d6e75e2f2bd9f51b1246e546d88addca0106bd/certifi-2025.4.26-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests>=2.31->yfinance) (1.26.16)\n",
      "Requirement already satisfied: pycparser in c:\\python\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Using cached yfinance-0.2.61-py2.py3-none-any.whl (117 kB)\n",
      "Using cached curl_cffi-0.11.1-cp39-abi3-win_amd64.whl (1.4 MB)\n",
      "Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: protobuf, certifi, curl_cffi, yfinance\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.7.22\n",
      "    Uninstalling certifi-2023.7.22:\n",
      "      Successfully uninstalled certifi-2023.7.22\n",
      "  Attempting uninstall: yfinance\n",
      "    Found existing installation: yfinance 0.2.33\n",
      "    Uninstalling yfinance-0.2.33:\n",
      "      Successfully uninstalled yfinance-0.2.33\n",
      "Successfully installed certifi-2025.4.26 curl_cffi-0.11.1 protobuf-6.31.1 yfinance-0.2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "polygon-api-client 1.14.5 requires websockets<15.0,>=10.3, but you have websockets 15.0.1 which is incompatible.\n",
      "pyppeteer 2.0.0 requires websockets<11.0,>=10.0, but you have websockets 15.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed0c33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = yf.Ticker(\"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96aa3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft.financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a93859c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_datareader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data \u001b[38;5;28;01mas\u001b[39;00m pdr\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5156e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_datareader\n",
      "  Obtaining dependency information for pandas_datareader from https://files.pythonhosted.org/packages/3f/16/56c9d648b503619ebe96f726b5f642b68e299b34162ed2d6faa9d7966b7d/pandas_datareader-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: lxml in c:\\python\\lib\\site-packages (from pandas_datareader) (4.9.3)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\python\\lib\\site-packages (from pandas_datareader) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\python\\lib\\site-packages (from pandas_datareader) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\python\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (1.24.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_datareader) (1.16.0)\n",
      "Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "   ---------------------------------------- 0.0/109.5 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/109.5 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 41.0/109.5 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.5/109.5 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pandas_datareader\n",
      "Successfully installed pandas_datareader-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d32fbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f56014d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pdr\u001b[38;5;241m.\u001b[39mget_data_yahoo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m\"\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2017-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2017-04-30\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\pandas_datareader\\data.py:80\u001b[0m, in \u001b[0;36mget_data_yahoo\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_yahoo\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m YahooDailyReader(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\pandas_datareader\\base.py:253\u001b[0m, in \u001b[0;36m_DailyBaseReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# If a single symbol, (e.g., 'GOOG')\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbols, (string_types, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m--> 253\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_one_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbols))\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbols, DataFrame):\n",
      "File \u001b[1;32mC:\\Python\\Lib\\site-packages\\pandas_datareader\\yahoo\\daily.py:152\u001b[0m, in \u001b[0;36mYahooDailyReader._read_one_data\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    150\u001b[0m ptrn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.App\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.main = (.*?);\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(this\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m);\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     j \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(re\u001b[38;5;241m.\u001b[39msearch(ptrn, resp\u001b[38;5;241m.\u001b[39mtext, re\u001b[38;5;241m.\u001b[39mDOTALL)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    153\u001b[0m     data \u001b[38;5;241m=\u001b[39m j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdispatcher\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstores\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHistoricalPriceStore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "data = pdr.get_data_yahoo(\"MSFT\", start=\"2017-01-01\", end=\"2017-04-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5e3d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: yfinanceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 0.2.61\n",
      "Summary: Download market data from Yahoo! Finance API\n",
      "Home-page: https://github.com/ranaroussi/yfinance\n",
      "Author: Ran Aroussi\n",
      "Author-email: ran@aroussi.com\n",
      "License: Apache\n",
      "Location: C:\\Python\\Lib\\site-packages\n",
      "Requires: beautifulsoup4, curl_cffi, frozendict, multitasking, numpy, pandas, peewee, platformdirs, protobuf, pytz, requests, websockets\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d9cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
