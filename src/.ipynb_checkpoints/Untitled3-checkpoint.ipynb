{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fbcdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gte\n",
      "Test Process_Stock\n",
      "Test\n",
      "Test\n",
      "Test2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error processing AAPL: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in train_pytorch_forecast for AAPL_Close horizon 1: positional indexers are out-of-bounds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dash import Dash, html, dcc, dash_table\n",
    "import plotly.express as px\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE, MAE, and RÂ².\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "class StockPriceNN(nn.Module):\n",
    "    \"\"\"Feed-forward neural network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(StockPriceNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class StockPriceLSTM(nn.Module):\n",
    "    \"\"\"LSTM network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super(StockPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_pytorch_forecast(data_path, target, selected_features, horizon=1, params=None, use_lstm=False):\n",
    "    \"\"\"Train PyTorch model for h-month-ahead forecasting.\"\"\"\n",
    "    print(\"Test: Entering train_pytorch_forecast\")\n",
    "    if params is None:\n",
    "        params = {'hidden_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(data_path)\n",
    "        logger.info(f\"Loaded data for {target} with shape {df.shape}\")\n",
    "        if target not in df.columns:\n",
    "            logger.error(f\"Target column {target} not found in data.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "        if df[target].isna().any():\n",
    "            logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "            df = df.dropna(subset=[target])\n",
    "            if df.empty:\n",
    "                logger.error(f\"No valid data for {target} after numeric conversion.\")\n",
    "                return None, None, None\n",
    "        logger.info(f\"Target {target} dtype: {df[target].dtype}\")\n",
    "\n",
    "        if len(df) < horizon:\n",
    "            logger.error(f\"Dataset too short ({len(df)} rows) for horizon {horizon}.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target + f'_t{horizon}'] = df[target].shift(-horizon)\n",
    "        df = df.dropna(subset=selected_features + [target + f'_t{horizon}'])\n",
    "        logger.info(f\"Data shape after NaN handling: {df.shape}\")\n",
    "        if df.empty:\n",
    "            logger.error(f\"No valid data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        X = df[selected_features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        y = df[target + f'_t{horizon}']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "        logger.info(f\"Train indices: {X_train.index[:5].tolist()}, Test indices: {X_test.index[:5].tolist()}\")\n",
    "        y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "        y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "        non_nan_train = ~y_train.isna()\n",
    "        non_nan_test = ~y_test.isna()\n",
    "        X_train = X_train[non_nan_train]\n",
    "        y_train = y_train[non_nan_train]\n",
    "        X_test = X_test[non_nan_test]\n",
    "        y_test = y_test[non_nan_test]\n",
    "        logger.info(f\"Train size after NaN filter: {len(X_train)}, Test size after NaN filter: {len(X_test)}\")\n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            logger.error(f\"No valid train/test data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        print(\"Test2: Before scaling\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if use_lstm:\n",
    "            # Reshape for LSTM [samples, timesteps, features]\n",
    "            X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "            X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "        X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "        y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "        y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "        input_size = X.shape[1]\n",
    "        model = StockPriceLSTM(input_size, params['hidden_size']) if use_lstm else StockPriceNN(input_size, params['hidden_size'])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        mlflow.set_experiment(\"stock_price_forecasting\")\n",
    "        with mlflow.start_run(run_name=f\"{target}_horizon{horizon}\"):\n",
    "            mlflow.set_tag(\"ticker\", target.split('_')[0])\n",
    "            mlflow.set_tag(\"horizon\", horizon)\n",
    "            mlflow.set_tag(\"model_type\", \"LSTM\" if use_lstm else \"NN\")\n",
    "            model.train()\n",
    "            for epoch in range(params['epochs']):\n",
    "                for i in range(0, len(X_train_tensor), params['batch_size']):\n",
    "                    batch_X = X_train_tensor[i:i + params['batch_size']]\n",
    "                    batch_y = y_train_tensor[i:i + params['batch_size']]\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    logger.info(f\"Epoch {epoch+1}/{params['epochs']} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_test_tensor).numpy().flatten()\n",
    "            # Bias correction\n",
    "            with torch.no_grad():\n",
    "                y_train_pred = model(X_train_tensor).numpy().flatten()\n",
    "            bias = np.mean(y_train_pred - y_train)\n",
    "            y_pred += bias\n",
    "            metrics = calculate_metrics(y_test, y_pred)\n",
    "            logger.info(f\"Metrics for {target} (horizon {horizon}): {metrics}\")\n",
    "\n",
    "            current_prices = df.loc[y_test.index, target]\n",
    "            logger.info(f\"Current prices shape: {current_prices.shape}, y_test shape: {y_test.shape}\")\n",
    "            price_change = (y_pred - current_prices) / current_prices * 100\n",
    "            signals = np.where(price_change > 5, \"Buy\", np.where(price_change < -5, \"Sell\", \"Hold\"))\n",
    "            backtest_df = pd.DataFrame({\n",
    "                \"Date\": y_test.index,\n",
    "                \"Actual\": y_test,\n",
    "                \"Predicted\": y_pred,\n",
    "                \"Current_Price\": current_prices,\n",
    "                \"Signal\": signals\n",
    "            })\n",
    "            backtest_df.to_csv(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.log_param(\"features\", \", \".join(selected_features))\n",
    "            mlflow.log_artifact(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.pytorch.log_model(model, \"pytorch_model\", input_example=X_train_scaled[:1])\n",
    "            model_uri = f\"runs:/{mlflow.active_run().info.run_id}/pytorch_model\"\n",
    "            registered_model = mlflow.register_model(model_uri, f\"StockPricePyTorch_Horizon{horizon}\")\n",
    "            logger.info(f\"Model registered: {registered_model.name} version {registered_model.version}\")\n",
    "\n",
    "        return model, metrics, backtest_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        logger.error(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def getStockFeatures(ticker=\"AAPL\"):\n",
    "    print(\"Test: Entering getStockFeatures\")\n",
    "    \"\"\"Get top 10 features for a stock using Random Forest.\"\"\"\n",
    "    data_path = Path(f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\")\n",
    "    if not data_path.exists():\n",
    "        logger.error(f\"Data file for {ticker} not found at {data_path}.\")\n",
    "        return []\n",
    "    df = pd.read_parquet(data_path)\n",
    "    target = f\"{ticker}_Close\"\n",
    "    if target not in df.columns:\n",
    "        logger.error(f\"Target column {target} not found in data for {ticker}.\")\n",
    "        return []\n",
    "    df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "    if df[target].isna().any():\n",
    "        logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "        df = df.dropna(subset=[target])\n",
    "    features = [col for col in df.columns if col != target and not col.startswith(target + '_t')]\n",
    "    logger.info(f\"Found {len(features)} features for {ticker}: {features}\")\n",
    "    if not features:\n",
    "        logger.error(f\"No valid features found for {ticker}.\")\n",
    "        return []\n",
    "\n",
    "    df = df.dropna(subset=features + [target])\n",
    "    logger.info(f\"Data shape after NaN handling for {ticker}: {df.shape}\")\n",
    "    if df.empty:\n",
    "        logger.error(f\"No valid data for {ticker} after NaN handling.\")\n",
    "        return []\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    cv_scores = cross_val_score(rf, X_train_scaled, y_train, cv=5, scoring=\"r2\")\n",
    "    logger.info(f\"Cross-validated R-squared for {ticker}: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    importances = rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    return importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "def process_stock(ticker, horizons=[1, 3]):\n",
    "    print(\"Test: Entering process_stock\")\n",
    "    \"\"\"Process a single stock.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting processing for {ticker}\")\n",
    "        top_features = getStockFeatures(ticker)\n",
    "        if not top_features:\n",
    "            logger.error(f\"No features returned for {ticker}.\")\n",
    "            return None\n",
    "        results = []\n",
    "        model_path = f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\"\n",
    "        target_col = f\"{ticker}_Close\"\n",
    "        for horizon in horizons:\n",
    "            logger.info(f\"Training model for {ticker} horizon {horizon}\")\n",
    "            use_lstm = (horizon == 3)  # Use LSTM for 3-month horizon\n",
    "            model, metrics, backtest_df = train_pytorch_forecast(model_path, target_col, top_features, horizon, use_lstm=use_lstm)\n",
    "            if metrics is None:\n",
    "                logger.error(f\"Failed to train model for {ticker} horizon {horizon}\")\n",
    "                continue\n",
    "            results.append({\n",
    "                'ticker': ticker,\n",
    "                'horizon': horizon,\n",
    "                'rmse': metrics['rmse'],\n",
    "                'mae': metrics['mae'],\n",
    "                'r2': metrics['r2'],\n",
    "                'top_features': top_features,\n",
    "                'backtest_df': backtest_df\n",
    "            })\n",
    "        logger.info(f\"Completed processing for {ticker} with {len(results)} results\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_dashboard(results):\n",
    "    \"\"\"Create a Dash dashboard for buy/sell signals.\"\"\"\n",
    "    app = Dash(__name__)\n",
    "    children = [\n",
    "        html.H1(\"Stock Price Prediction Dashboard\"),\n",
    "        html.H2(\"Top Stocks by RÂ²\")\n",
    "    ]\n",
    "    \n",
    "    for result in results:\n",
    "        ticker = result['ticker']\n",
    "        horizon = result['horizon']\n",
    "        backtest_df = result['backtest_df']\n",
    "        fig = px.line(backtest_df, x=\"Date\", y=[\"Actual\", \"Predicted\"], title=f\"{ticker} {horizon}-Month Forecast\")\n",
    "        fig.add_scatter(x=backtest_df[backtest_df[\"Signal\"] == \"Buy\"][\"Date\"],\n",
    "                        y=backtest_df[backtest_df[\"Signal\"] == \"Buy\"][\"Predicted\"],\n",
    "                        mode=\"markers\", name=\"Buy\", marker=dict(symbol=\"triangle-up\", size=10, color=\"green\"))\n",
    "        fig.add_scatter(x=backtest_df[backtest_df[\"Signal\"] == \"Sell\"][\"Date\"],\n",
    "                        y=backtest_df[backtest_df[\"Signal\"] == \"Sell\"][\"Predicted\"],\n",
    "                        mode=\"markers\", name=\"Sell\", marker=dict(symbol=\"triangle-down\", size=10, color=\"red\"))\n",
    "        children.append(html.H3(f\"{ticker} (Horizon: {horizon} months, RÂ²: {result['r2']:.3f})\"))\n",
    "        children.append(dcc.Graph(figure=fig))\n",
    "        children.append(dash_table.DataTable(\n",
    "            data=backtest_df.to_dict('records'),\n",
    "            columns=[{\"name\": i, \"id\": i} for i in backtest_df.columns],\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            page_size=10\n",
    "        ))\n",
    "        children.append(html.Hr())\n",
    "\n",
    "    app.layout = html.Div(children)\n",
    "    app.run(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Test: Main block\")\n",
    "    tickers = pd.read_csv(\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/src/data/equities.csv\")['Symbol'].tolist()\n",
    "    logger.info(f\"Processing {len(tickers)} tickers: {tickers}\")\n",
    "    # Process a single ticker for testing\n",
    "    results = process_stock(\"AAPL\")\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    if results:\n",
    "        # Create dashboard for AAPL\n",
    "        create_dashboard(results)\n",
    "        \n",
    "        # Process all tickers\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_stock)(ticker) for ticker in tickers)  # Limit for demo\n",
    "        results = [r for r in sum([r if r else [] for r in results], []) if r is not None]\n",
    "        results_df = pd.DataFrame(results)\n",
    "        if not results_df.empty:\n",
    "            logger.info(f\"Results DataFrame shape: {results_df.shape}\")\n",
    "            top_10 = results_df.sort_values(by='r2', ascending=False).head(10)\n",
    "            logger.info(f\"Top 10 models by RÂ²:\\n{top_10[['ticker', 'horizon', 'r2', 'rmse', 'mae']]}\")\n",
    "            top_10.to_csv(\"top_10_forecasts_by_r2.csv\", index=False)\n",
    "\n",
    "            with mlflow.start_run(run_name=\"Top_10_Forecasts_Summary\"):\n",
    "                mlflow.log_artifact(\"top_10_forecasts_by_r2.csv\")\n",
    "                for i, row in top_10.iterrows():\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_r2\", row['r2'])\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_rmse\", row['rmse'])\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_mae\", row['mae'])\n",
    "\n",
    "            create_dashboard(results)  # Dashboard for all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc431d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce69fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Main block\n",
      "Test: Entering process_stock\n",
      "Test: Entering getStockFeatures\n",
      "Test: Entering train_pytorch_forecast\n",
      "Test2: Before scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 13:09:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'StockPricePyTorch_Horizon1'.\n",
      "Created version '1' of model 'StockPricePyTorch_Horizon1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Entering train_pytorch_forecast\n",
      "Test2: Before scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 13:09:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [{'ticker': 'AAPL', 'horizon': 1, 'rmse': 27.225903644664307, 'mae': 23.55388609599129, 'r2': 0.5352345684363038, 'top_features': ['AAPL_Close_ma3', 'SRVPRD_lag1', 'AAPL_Close_lag1', 'PAYEMS_lag1', 'BUSINV_lag3', 'SRVPRD_lag3', 'CPIAUCSL_lag6', 'CSUSHPINSA', 'PI_lag1', 'CIVPART'], 'backtest_df':                  Date    Actual   Predicted  Current_Price Signal\n",
      "2020-04-01 2020-04-01   77.0563   65.145096        71.2057   Sell\n",
      "2020-05-01 2020-05-01   88.6527   71.925064        77.0563   Sell\n",
      "2020-06-01 2020-06-01  103.2921   74.301880        88.6527   Sell\n",
      "2020-07-01 2020-07-01  125.4358   83.765152       103.2921   Sell\n",
      "2020-08-01 2020-08-01  112.7783   93.105011       125.4358   Sell\n",
      "...               ...       ...         ...            ...    ...\n",
      "2024-12-01 2024-12-01  235.4321  203.603836       249.8174   Sell\n",
      "2025-01-01 2025-01-01  241.2580  208.146225       235.4321   Sell\n",
      "2025-02-01 2025-02-01  221.8391  206.212189       241.2580   Sell\n",
      "2025-03-01 2025-03-01  212.2217  203.539185       221.8391   Sell\n",
      "2025-04-01 2025-04-01  199.2700  196.237869       212.2217   Sell\n",
      "\n",
      "[61 rows x 5 columns]}, {'ticker': 'AAPL', 'horizon': 3, 'rmse': 39.64185628568782, 'mae': 35.286254764344264, 'r2': 0.014680273427412516, 'top_features': ['AAPL_Close_ma3', 'SRVPRD_lag1', 'AAPL_Close_lag1', 'PAYEMS_lag1', 'BUSINV_lag3', 'SRVPRD_lag3', 'CPIAUCSL_lag6', 'CSUSHPINSA', 'PI_lag1', 'CIVPART'], 'backtest_df':                  Date    Actual   Predicted  Current_Price Signal\n",
      "2020-02-01 2020-02-01   77.0563   71.386497        66.0950    Buy\n",
      "2020-03-01 2020-03-01   88.6527   68.621162        61.6300    Buy\n",
      "2020-04-01 2020-04-01  103.2921   64.996696        71.2057   Sell\n",
      "2020-05-01 2020-05-01  125.4358   61.402420        77.0563   Sell\n",
      "2020-06-01 2020-06-01  112.7783   64.082947        88.6527   Sell\n",
      "...               ...       ...         ...            ...    ...\n",
      "2024-10-01 2024-10-01  235.4321  189.971603       225.1187   Sell\n",
      "2024-11-01 2024-11-01  241.2580  189.289734       236.4987   Sell\n",
      "2024-12-01 2024-12-01  221.8391  194.085815       249.8174   Sell\n",
      "2025-01-01 2025-01-01  212.2217  198.701111       235.4321   Sell\n",
      "2025-02-01 2025-02-01  199.2700  195.895523       241.2580   Sell\n",
      "\n",
      "[61 rows x 5 columns]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'StockPricePyTorch_Horizon3'.\n",
      "Created version '1' of model 'StockPricePyTorch_Horizon3'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE, MAE, and RÂ².\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "class StockPriceNN(nn.Module):\n",
    "    \"\"\"Feed-forward neural network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(StockPriceNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_pytorch_forecast(data_path, target, selected_features, horizon=1, params=None):\n",
    "    \"\"\"Train PyTorch model for h-month-ahead forecasting.\"\"\"\n",
    "    print(\"Test: Entering train_pytorch_forecast\")\n",
    "    if params is None:\n",
    "        params = {'hidden_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(data_path)\n",
    "        logger.info(f\"Loaded data for {target} with shape {df.shape}\")\n",
    "        if target not in df.columns:\n",
    "            logger.error(f\"Target column {target} not found in data.\")\n",
    "            return None, None, None\n",
    "\n",
    "        # Convert target to numeric, handling strings\n",
    "        df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "        if df[target].isna().any():\n",
    "            logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "            df = df.dropna(subset=[target])\n",
    "            if df.empty:\n",
    "                logger.error(f\"No valid data for {target} after numeric conversion.\")\n",
    "                return None, None, None\n",
    "        logger.info(f\"Target {target} dtype after conversion: {df[target].dtype}\")\n",
    "\n",
    "        if len(df) < horizon:\n",
    "            logger.error(f\"Dataset too short ({len(df)} rows) for horizon {horizon}.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target + f'_t{horizon}'] = df[target].shift(-horizon)\n",
    "        df = df.dropna(subset=selected_features + [target + f'_t{horizon}'])\n",
    "        logger.info(f\"Data shape after NaN handling: {df.shape}\")\n",
    "        if df.empty:\n",
    "            logger.error(f\"No valid data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        X = df[selected_features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        y = df[target + f'_t{horizon}']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "        logger.info(f\"Train indices: {X_train.index[:5].tolist()}, Test indices: {X_test.index[:5].tolist()}\")\n",
    "        y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "        y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "        non_nan_train = ~y_train.isna()\n",
    "        non_nan_test = ~y_test.isna()\n",
    "        X_train = X_train[non_nan_train]\n",
    "        y_train = y_train[non_nan_train]\n",
    "        X_test = X_test[non_nan_test]\n",
    "        y_test = y_test[non_nan_test]\n",
    "        logger.info(f\"Train size after NaN filter: {len(X_train)}, Test size after NaN filter: {len(X_test)}\")\n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            logger.error(f\"No valid train/test data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        print(\"Test2: Before scaling\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "        y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "        y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "        input_size = X.shape[1]\n",
    "        model = StockPriceNN(input_size, params['hidden_size'])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        mlflow.set_experiment(\"stock_price_forecasting\")\n",
    "        with mlflow.start_run(run_name=f\"{target}_horizon{horizon}\"):\n",
    "            mlflow.set_tag(\"ticker\", target.split('_')[0])\n",
    "            mlflow.set_tag(\"horizon\", horizon)\n",
    "            model.train()\n",
    "            for epoch in range(params['epochs']):\n",
    "                for i in range(0, len(X_train_tensor), params['batch_size']):\n",
    "                    batch_X = X_train_tensor[i:i + params['batch_size']]\n",
    "                    batch_y = y_train_tensor[i:i + params['batch_size']]\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    logger.info(f\"Epoch {epoch+1}/{params['epochs']} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_test_tensor).numpy().flatten()\n",
    "            metrics = calculate_metrics(y_test, y_pred)\n",
    "            logger.info(f\"Metrics for {target} (horizon {horizon}): {metrics}\")\n",
    "\n",
    "            current_prices = df.loc[y_test.index, target]\n",
    "            logger.info(f\"Current prices shape: {current_prices.shape}, y_test shape: {y_test.shape}\")\n",
    "            price_change = (y_pred - current_prices) / current_prices * 100\n",
    "            signals = np.where(price_change > 5, \"Buy\", np.where(price_change < -5, \"Sell\", \"Hold\"))\n",
    "            backtest_df = pd.DataFrame({\n",
    "                \"Date\": y_test.index,\n",
    "                \"Actual\": y_test,\n",
    "                \"Predicted\": y_pred,\n",
    "                \"Current_Price\": current_prices,\n",
    "                \"Signal\": signals\n",
    "            })\n",
    "            backtest_df.to_csv(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.log_param(\"features\", \", \".join(selected_features))\n",
    "            mlflow.log_artifact(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.pytorch.log_model(model, \"pytorch_model\")\n",
    "            model_uri = f\"runs:/{mlflow.active_run().info.run_id}/pytorch_model\"\n",
    "            registered_model = mlflow.register_model(model_uri, f\"StockPricePyTorch_Horizon{horizon}\")\n",
    "            logger.info(f\"Model registered: {registered_model.name} version {registered_model.version}\")\n",
    "\n",
    "        return model, metrics, backtest_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        logger.error(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def getStockFeatures(ticker=\"AAPL\"):\n",
    "    print(\"Test: Entering getStockFeatures\")\n",
    "    \"\"\"Get top 10 features for a stock using Random Forest.\"\"\"\n",
    "    data_path = Path(f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\")\n",
    "    if not data_path.exists():\n",
    "        logger.error(f\"Data file for {ticker} not found at {data_path}.\")\n",
    "        return []\n",
    "    df = pd.read_parquet(data_path)\n",
    "    target = f\"{ticker}_Close\"\n",
    "    if target not in df.columns:\n",
    "        logger.error(f\"Target column {target} not found in data for {ticker}.\")\n",
    "        return []\n",
    "    # Convert target to numeric in feature selection\n",
    "    df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "    if df[target].isna().any():\n",
    "        logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "        df = df.dropna(subset=[target])\n",
    "    features = [col for col in df.columns if col != target and not col.startswith(target + '_t')]\n",
    "    logger.info(f\"Found {len(features)} features for {ticker}: {features}\")\n",
    "    if not features:\n",
    "        logger.error(f\"No valid features found for {ticker}.\")\n",
    "        return []\n",
    "\n",
    "    df = df.dropna(subset=features + [target])\n",
    "    logger.info(f\"Data shape after NaN handling for {ticker}: {df.shape}\")\n",
    "    if df.empty:\n",
    "        logger.error(f\"No valid data for {ticker} after NaN handling.\")\n",
    "        return []\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    cv_scores = cross_val_score(rf, X_train_scaled, y_train, cv=5, scoring=\"r2\")\n",
    "    logger.info(f\"Cross-validated R-squared for {ticker}: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    importances = rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    return importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "def process_stock(ticker, horizons=[1, 3]):\n",
    "    print(\"Test: Entering process_stock\")\n",
    "    \"\"\"Process a single stock.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting processing for {ticker}\")\n",
    "        top_features = getStockFeatures(ticker)\n",
    "        if not top_features:\n",
    "            logger.error(f\"No features returned for {ticker}.\")\n",
    "            return None\n",
    "        results = []\n",
    "        model_path = f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\"\n",
    "        target_col = f\"{ticker}_Close\"\n",
    "        for horizon in horizons:\n",
    "            logger.info(f\"Training model for {ticker} horizon {horizon}\")\n",
    "            model, metrics, backtest_df = train_pytorch_forecast(model_path, target_col, top_features, horizon)\n",
    "            if metrics is None:\n",
    "                logger.error(f\"Failed to train model for {ticker} horizon {horizon}\")\n",
    "                continue\n",
    "            results.append({\n",
    "                'ticker': ticker,\n",
    "                'horizon': horizon,\n",
    "                'rmse': metrics['rmse'],\n",
    "                'mae': metrics['mae'],\n",
    "                'r2': metrics['r2'],\n",
    "                'top_features': top_features,\n",
    "                'backtest_df': backtest_df\n",
    "            })\n",
    "        logger.info(f\"Completed processing for {ticker} with {len(results)} results\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Test: Main block\")\n",
    "    tickers = pd.read_csv(\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/src/data/equities.csv\")['Symbol'].tolist()\n",
    "    logger.info(f\"Processing {len(tickers)} tickers: {tickers}\")\n",
    "    results = process_stock(\"AAPL\")\n",
    "    print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1f4f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]['backtest_df']['CorrectMove'] = np.where(\n",
    "    results[1]['backtest_df']['Actual'] > results[1]['backtest_df']['Current_Price'],\n",
    "    'Buy',\n",
    "    'Sell'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75549db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Signal</th>\n",
       "      <th>CorrectMove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>77.0563</td>\n",
       "      <td>71.386497</td>\n",
       "      <td>66.0950</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>88.6527</td>\n",
       "      <td>68.621162</td>\n",
       "      <td>61.6300</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>103.2921</td>\n",
       "      <td>64.996696</td>\n",
       "      <td>71.2057</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>125.4358</td>\n",
       "      <td>61.402420</td>\n",
       "      <td>77.0563</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>112.7783</td>\n",
       "      <td>64.082947</td>\n",
       "      <td>88.6527</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>235.4321</td>\n",
       "      <td>189.971603</td>\n",
       "      <td>225.1187</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>241.2580</td>\n",
       "      <td>189.289734</td>\n",
       "      <td>236.4987</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>221.8391</td>\n",
       "      <td>194.085815</td>\n",
       "      <td>249.8174</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>212.2217</td>\n",
       "      <td>198.701111</td>\n",
       "      <td>235.4321</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>199.2700</td>\n",
       "      <td>195.895523</td>\n",
       "      <td>241.2580</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date    Actual   Predicted  Current_Price Signal CorrectMove\n",
       "2020-02-01 2020-02-01   77.0563   71.386497        66.0950    Buy         Buy\n",
       "2020-03-01 2020-03-01   88.6527   68.621162        61.6300    Buy         Buy\n",
       "2020-04-01 2020-04-01  103.2921   64.996696        71.2057   Sell         Buy\n",
       "2020-05-01 2020-05-01  125.4358   61.402420        77.0563   Sell         Buy\n",
       "2020-06-01 2020-06-01  112.7783   64.082947        88.6527   Sell         Buy\n",
       "...               ...       ...         ...            ...    ...         ...\n",
       "2024-10-01 2024-10-01  235.4321  189.971603       225.1187   Sell         Buy\n",
       "2024-11-01 2024-11-01  241.2580  189.289734       236.4987   Sell         Buy\n",
       "2024-12-01 2024-12-01  221.8391  194.085815       249.8174   Sell        Sell\n",
       "2025-01-01 2025-01-01  212.2217  198.701111       235.4321   Sell        Sell\n",
       "2025-02-01 2025-02-01  199.2700  195.895523       241.2580   Sell        Sell\n",
       "\n",
       "[61 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]['backtest_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd818381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Main block\n",
      "Test: Entering process_stock\n",
      "Test: Entering getStockFeatures\n",
      "Test: Entering train_pytorch_forecast\n",
      "Test2: Before scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 13:23:22 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: RuntimeError('mat1 and mat2 must have the same dtype, but got Double and Float'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f238bb435184c459400281310836778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 13:23:28 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      -0.8105476339471039,\n",
      "      -1.4510651868949207,\n",
      "      -0.8141476593511862,\n",
      "      -0.93939120974452,\n",
      "      -1.270227241772032,\n",
      "      -1.4367792847944094,\n",
      "      -1.7236754234136695,\n",
      "      -2.0716649718066393,\n",
      "      -1.5348917661101735,\n",
      "      1.6610900059066525\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: mat1 and mat2 must have the same dtype, but got Double and Float\n",
      "Registered model 'StockPricePyTorch_Horizon1' already exists. Creating a new version of this model...\n",
      "Created version '13' of model 'StockPricePyTorch_Horizon1'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Entering train_pytorch_forecast\n",
      "Test2: Before scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 13:23:32 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: ValueError('input must have the type torch.float32, got type torch.float64'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fd823594da411aac9829c5a990398d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 13:23:37 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      [\n",
      "        -0.8195741568753288,\n",
      "        -1.455247777830105,\n",
      "        -0.8248169877221491,\n",
      "        -0.9379360211673813,\n",
      "        -1.2680000427246219,\n",
      "        -1.4407257544237047,\n",
      "        -1.7225549365198587,\n",
      "        -2.0792044439367303,\n",
      "        -1.5388311510898904,\n",
      "        1.6537812645384349\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: input must have the type torch.float32, got type torch.float64\n",
      "Registered model 'StockPricePyTorch_Horizon3' already exists. Creating a new version of this model...\n",
      "Created version '13' of model 'StockPricePyTorch_Horizon3'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [{'ticker': 'AAPL', 'horizon': 1, 'rmse': 27.32069282759836, 'mae': 23.51427765653016, 'r2': 0.5319926980359542, 'top_features': ['AAPL_Close_ma3', 'SRVPRD_lag1', 'AAPL_Close_lag1', 'PAYEMS_lag1', 'BUSINV_lag3', 'SRVPRD_lag3', 'CPIAUCSL_lag6', 'CSUSHPINSA', 'PI_lag1', 'CIVPART'], 'backtest_df':                  Date    Actual   Predicted  Current_Price Signal\n",
      "2020-04-01 2020-04-01   77.0563   65.406296        71.2057   Sell\n",
      "2020-05-01 2020-05-01   88.6527   77.694702        77.0563   Hold\n",
      "2020-06-01 2020-06-01  103.2921   79.363571        88.6527   Sell\n",
      "2020-07-01 2020-07-01  125.4358   84.844360       103.2921   Sell\n",
      "2020-08-01 2020-08-01  112.7783   93.349678       125.4358   Sell\n",
      "...               ...       ...         ...            ...    ...\n",
      "2024-12-01 2024-12-01  235.4321  203.717346       249.8174   Sell\n",
      "2025-01-01 2025-01-01  241.2580  209.173309       235.4321   Sell\n",
      "2025-02-01 2025-02-01  221.8391  205.809631       241.2580   Sell\n",
      "2025-03-01 2025-03-01  212.2217  204.606842       221.8391   Sell\n",
      "2025-04-01 2025-04-01  199.2700  196.175354       212.2217   Sell\n",
      "\n",
      "[61 rows x 5 columns]}, {'ticker': 'AAPL', 'horizon': 3, 'rmse': 135.2295690985794, 'mae': 129.20005832319418, 'r2': -10.466015922872828, 'top_features': ['AAPL_Close_ma3', 'SRVPRD_lag1', 'AAPL_Close_lag1', 'PAYEMS_lag1', 'BUSINV_lag3', 'SRVPRD_lag3', 'CPIAUCSL_lag6', 'CSUSHPINSA', 'PI_lag1', 'CIVPART'], 'backtest_df':                  Date    Actual  Predicted  Current_Price Signal\n",
      "2020-02-01 2020-02-01   77.0563  35.210777        66.0950   Sell\n",
      "2020-03-01 2020-03-01   88.6527  35.201401        61.6300   Sell\n",
      "2020-04-01 2020-04-01  103.2921  35.184090        71.2057   Sell\n",
      "2020-05-01 2020-05-01  125.4358  35.172787        77.0563   Sell\n",
      "2020-06-01 2020-06-01  112.7783  35.199272        88.6527   Sell\n",
      "...               ...       ...        ...            ...    ...\n",
      "2024-10-01 2024-10-01  235.4321  35.233608       225.1187   Sell\n",
      "2024-11-01 2024-11-01  241.2580  35.233601       236.4987   Sell\n",
      "2024-12-01 2024-12-01  221.8391  35.233631       249.8174   Sell\n",
      "2025-01-01 2025-01-01  212.2217  35.233658       235.4321   Sell\n",
      "2025-02-01 2025-02-01  199.2700  35.233643       241.2580   Sell\n",
      "\n",
      "[61 rows x 5 columns]}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x266baf18690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "C:\\Python\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "C:\\Python\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "C:\\Python\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "C:\\Python\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x266c7039e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dash import Dash, html, dcc, dash_table\n",
    "import plotly.express as px\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSE, MAE, and RÂ².\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "class StockPriceNN(nn.Module):\n",
    "    \"\"\"Feed-forward neural network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(StockPriceNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class StockPriceLSTM(nn.Module):\n",
    "    \"\"\"LSTM network for stock price forecasting.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super(StockPriceLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_pytorch_forecast(data_path, target, selected_features, horizon=1, params=None, use_lstm=False):\n",
    "    \"\"\"Train PyTorch model for h-month-ahead forecasting.\"\"\"\n",
    "    print(\"Test: Entering train_pytorch_forecast\")\n",
    "    if params is None:\n",
    "        params = {'hidden_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'batch_size': 16}\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(data_path)\n",
    "        logger.info(f\"Loaded data for {target} with shape {df.shape}\")\n",
    "        if target not in df.columns:\n",
    "            logger.error(f\"Target column {target} not found in data.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "        if df[target].isna().any():\n",
    "            logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "            df = df.dropna(subset=[target])\n",
    "            if df.empty:\n",
    "                logger.error(f\"No valid data for {target} after numeric conversion.\")\n",
    "                return None, None, None\n",
    "        logger.info(f\"Target {target} dtype: {df[target].dtype}\")\n",
    "\n",
    "        if len(df) < horizon:\n",
    "            logger.error(f\"Dataset too short ({len(df)} rows) for horizon {horizon}.\")\n",
    "            return None, None, None\n",
    "\n",
    "        df[target + f'_t{horizon}'] = df[target].shift(-horizon)\n",
    "        df = df.dropna(subset=selected_features + [target + f'_t{horizon}'])\n",
    "        logger.info(f\"Data shape after NaN handling: {df.shape}\")\n",
    "        if df.empty:\n",
    "            logger.error(f\"No valid data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        X = df[selected_features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        y = df[target + f'_t{horizon}']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "        logger.info(f\"Train indices: {X_train.index[:5].tolist()}, Test indices: {X_test.index[:5].tolist()}\")\n",
    "        y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "        y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "        non_nan_train = ~y_train.isna()\n",
    "        non_nan_test = ~y_test.isna()\n",
    "        X_train = X_train[non_nan_train]\n",
    "        y_train = y_train[non_nan_train]\n",
    "        X_test = X_test[non_nan_test]\n",
    "        y_test = y_test[non_nan_test]\n",
    "        logger.info(f\"Train size after NaN filter: {len(X_train)}, Test size after NaN filter: {len(X_test)}\")\n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            logger.error(f\"No valid train/test data for {target} after NaN handling.\")\n",
    "            return None, None, None\n",
    "\n",
    "        print(\"Test2: Before scaling\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if use_lstm:\n",
    "            # Reshape for LSTM [samples, timesteps, features]\n",
    "            X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "            X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "        X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "        y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "        y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "\n",
    "        input_size = X.shape[1]\n",
    "        model = StockPriceLSTM(input_size, params['hidden_size']) if use_lstm else StockPriceNN(input_size, params['hidden_size'])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        mlflow.set_experiment(\"stock_price_forecasting\")\n",
    "        with mlflow.start_run(run_name=f\"{target}_horizon{horizon}\"):\n",
    "            mlflow.set_tag(\"ticker\", target.split('_')[0])\n",
    "            mlflow.set_tag(\"horizon\", horizon)\n",
    "            mlflow.set_tag(\"model_type\", \"LSTM\" if use_lstm else \"NN\")\n",
    "            model.train()\n",
    "            for epoch in range(params['epochs']):\n",
    "                for i in range(0, len(X_train_tensor), params['batch_size']):\n",
    "                    batch_X = X_train_tensor[i:i + params['batch_size']]\n",
    "                    batch_y = y_train_tensor[i:i + params['batch_size']]\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    logger.info(f\"Epoch {epoch+1}/{params['epochs']} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_test_tensor).numpy().flatten()\n",
    "            # Bias correction\n",
    "            with torch.no_grad():\n",
    "                y_train_pred = model(X_train_tensor).numpy().flatten()\n",
    "            bias = np.mean(y_train_pred - y_train)\n",
    "            y_pred += bias\n",
    "            metrics = calculate_metrics(y_test, y_pred)\n",
    "            logger.info(f\"Metrics for {target} (horizon {horizon}): {metrics}\")\n",
    "\n",
    "            current_prices = df.loc[y_test.index, target]\n",
    "            logger.info(f\"Current prices shape: {current_prices.shape}, y_test shape: {y_test.shape}\")\n",
    "            price_change = (y_pred - current_prices) / current_prices * 100\n",
    "            signals = np.where(price_change > 5, \"Buy\", np.where(price_change < -5, \"Sell\", \"Hold\"))\n",
    "            backtest_df = pd.DataFrame({\n",
    "                \"Date\": y_test.index,\n",
    "                \"Actual\": y_test,\n",
    "                \"Predicted\": y_pred,\n",
    "                \"Current_Price\": current_prices,\n",
    "                \"Signal\": signals\n",
    "            })\n",
    "            backtest_df.to_csv(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.log_param(\"features\", \", \".join(selected_features))\n",
    "            mlflow.log_artifact(f\"backtest_{target}_horizon{horizon}.csv\")\n",
    "            mlflow.pytorch.log_model(model, \"pytorch_model\", input_example=X_train_scaled[:1])\n",
    "            model_uri = f\"runs:/{mlflow.active_run().info.run_id}/pytorch_model\"\n",
    "            registered_model = mlflow.register_model(model_uri, f\"StockPricePyTorch_Horizon{horizon}\")\n",
    "            logger.info(f\"Model registered: {registered_model.name} version {registered_model.version}\")\n",
    "\n",
    "        return model, metrics, backtest_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        logger.error(f\"Error in train_pytorch_forecast for {target} horizon {horizon}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def getStockFeatures(ticker=\"AAPL\"):\n",
    "    print(\"Test: Entering getStockFeatures\")\n",
    "    \"\"\"Get top 10 features for a stock using Random Forest.\"\"\"\n",
    "    data_path = Path(f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\")\n",
    "    if not data_path.exists():\n",
    "        logger.error(f\"Data file for {ticker} not found at {data_path}.\")\n",
    "        return []\n",
    "    df = pd.read_parquet(data_path)\n",
    "    target = f\"{ticker}_Close\"\n",
    "    if target not in df.columns:\n",
    "        logger.error(f\"Target column {target} not found in data for {ticker}.\")\n",
    "        return []\n",
    "    df[target] = pd.to_numeric(df[target], errors='coerce')\n",
    "    if df[target].isna().any():\n",
    "        logger.warning(f\"Target {target} contains {df[target].isna().sum()} NaN values after conversion.\")\n",
    "        df = df.dropna(subset=[target])\n",
    "    features = [col for col in df.columns if col != target and not col.startswith(target + '_t')]\n",
    "    logger.info(f\"Found {len(features)} features for {ticker}: {features}\")\n",
    "    if not features:\n",
    "        logger.error(f\"No valid features found for {ticker}.\")\n",
    "        return []\n",
    "\n",
    "    df = df.dropna(subset=features + [target])\n",
    "    logger.info(f\"Data shape after NaN handling for {ticker}: {df.shape}\")\n",
    "    if df.empty:\n",
    "        logger.error(f\"No valid data for {ticker} after NaN handling.\")\n",
    "        return []\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    cv_scores = cross_val_score(rf, X_train_scaled, y_train, cv=5, scoring=\"r2\")\n",
    "    logger.info(f\"Cross-validated R-squared for {ticker}: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    importances = rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    return importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "def process_stock(ticker, horizons=[1, 3]):\n",
    "    print(\"Test: Entering process_stock\")\n",
    "    \"\"\"Process a single stock.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting processing for {ticker}\")\n",
    "        top_features = getStockFeatures(ticker)\n",
    "        if not top_features:\n",
    "            logger.error(f\"No features returned for {ticker}.\")\n",
    "            return None\n",
    "        results = []\n",
    "        model_path = f\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/data/combined/{ticker}_combined.parquet\"\n",
    "        target_col = f\"{ticker}_Close\"\n",
    "        for horizon in horizons:\n",
    "            logger.info(f\"Training model for {ticker} horizon {horizon}\")\n",
    "            use_lstm = (horizon == 3)  # Use LSTM for 3-month horizon\n",
    "            model, metrics, backtest_df = train_pytorch_forecast(model_path, target_col, top_features, horizon, use_lstm=use_lstm)\n",
    "            if metrics is None:\n",
    "                logger.error(f\"Failed to train model for {ticker} horizon {horizon}\")\n",
    "                continue\n",
    "            results.append({\n",
    "                'ticker': ticker,\n",
    "                'horizon': horizon,\n",
    "                'rmse': metrics['rmse'],\n",
    "                'mae': metrics['mae'],\n",
    "                'r2': metrics['r2'],\n",
    "                'top_features': top_features,\n",
    "                'backtest_df': backtest_df\n",
    "            })\n",
    "        logger.info(f\"Completed processing for {ticker} with {len(results)} results\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_dashboard(results):\n",
    "    \"\"\"Create a Dash dashboard for buy/sell signals.\"\"\"\n",
    "    app = Dash(__name__)\n",
    "    children = [\n",
    "        html.H1(\"Stock Price Prediction Dashboard\"),\n",
    "        html.H2(\"Top Stocks by RÂ²\")\n",
    "    ]\n",
    "    \n",
    "    for result in results:\n",
    "        ticker = result['ticker']\n",
    "        horizon = result['horizon']\n",
    "        backtest_df = result['backtest_df']\n",
    "        fig = px.line(backtest_df, x=\"Date\", y=[\"Actual\", \"Predicted\"], title=f\"{ticker} {horizon}-Month Forecast\")\n",
    "        fig.add_scatter(x=backtest_df[backtest_df[\"Signal\"] == \"Buy\"][\"Date\"],\n",
    "                        y=backtest_df[backtest_df[\"Signal\"] == \"Buy\"][\"Predicted\"],\n",
    "                        mode=\"markers\", name=\"Buy\", marker=dict(symbol=\"triangle-up\", size=10, color=\"green\"))\n",
    "        fig.add_scatter(x=backtest_df[backtest_df[\"Signal\"] == \"Sell\"][\"Date\"],\n",
    "                        y=backtest_df[backtest_df[\"Signal\"] == \"Sell\"][\"Predicted\"],\n",
    "                        mode=\"markers\", name=\"Sell\", marker=dict(symbol=\"triangle-down\", size=10, color=\"red\"))\n",
    "        children.append(html.H3(f\"{ticker} (Horizon: {horizon} months, RÂ²: {result['r2']:.3f})\"))\n",
    "        children.append(dcc.Graph(figure=fig))\n",
    "        children.append(dash_table.DataTable(\n",
    "            data=backtest_df.to_dict('records'),\n",
    "            columns=[{\"name\": i, \"id\": i} for i in backtest_df.columns],\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            page_size=10\n",
    "        ))\n",
    "        children.append(html.Hr())\n",
    "\n",
    "    app.layout = html.Div(children)\n",
    "    app.run(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Test: Main block\")\n",
    "    tickers = pd.read_csv(\"C:/Users/Steel/Desktop/Projects/intel-sweep/intel-sweep/src/data/equities.csv\")['Symbol'].tolist()\n",
    "    logger.info(f\"Processing {len(tickers)} tickers: {tickers}\")\n",
    "    # Process a single ticker for testing\n",
    "    results = process_stock(\"AAPL\")\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    if results:\n",
    "        # Create dashboard for AAPL\n",
    "        create_dashboard(results)\n",
    "        \n",
    "        # Process all tickers\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_stock)(ticker) for ticker in tickers)  # Limit for demo\n",
    "        results = [r for r in sum([r if r else [] for r in results], []) if r is not None]\n",
    "        results_df = pd.DataFrame(results)\n",
    "        if not results_df.empty:\n",
    "            logger.info(f\"Results DataFrame shape: {results_df.shape}\")\n",
    "            top_10 = results_df.sort_values(by='r2', ascending=False).head(10)\n",
    "            logger.info(f\"Top 10 models by RÂ²:\\n{top_10[['ticker', 'horizon', 'r2', 'rmse', 'mae']]}\")\n",
    "            top_10.to_csv(\"top_10_forecasts_by_r2.csv\", index=False)\n",
    "\n",
    "            with mlflow.start_run(run_name=\"Top_10_Forecasts_Summary\"):\n",
    "                mlflow.log_artifact(\"top_10_forecasts_by_r2.csv\")\n",
    "                for i, row in top_10.iterrows():\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_r2\", row['r2'])\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_rmse\", row['rmse'])\n",
    "                    mlflow.log_metric(f\"{row['ticker']}_horizon{row['horizon']}_mae\", row['mae'])\n",
    "\n",
    "            create_dashboard(results)  # Dashboard for all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ff8698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>horizon</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>top_features</th>\n",
       "      <th>backtest_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "      <td>23.682996</td>\n",
       "      <td>15.688522</td>\n",
       "      <td>0.693331</td>\n",
       "      <td>[SP500_lag3, NVDA_Close_ma3, PAYEMS_lag1, RSXF...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>3</td>\n",
       "      <td>60.131066</td>\n",
       "      <td>42.047603</td>\n",
       "      <td>-0.976946</td>\n",
       "      <td>[SP500_lag3, NVDA_Close_ma3, PAYEMS_lag1, RSXF...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>1</td>\n",
       "      <td>38.066642</td>\n",
       "      <td>31.475942</td>\n",
       "      <td>0.761796</td>\n",
       "      <td>[CSUSHPINSA_lag6, CSUSHPINSA_lag3, CSUSHPINSA_...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>3</td>\n",
       "      <td>284.814116</td>\n",
       "      <td>273.926725</td>\n",
       "      <td>-12.334717</td>\n",
       "      <td>[CSUSHPINSA_lag6, CSUSHPINSA_lag3, CSUSHPINSA_...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>26.516358</td>\n",
       "      <td>22.643422</td>\n",
       "      <td>0.559144</td>\n",
       "      <td>[AAPL_Close_ma3, SRVPRD_lag1, AAPL_Close_lag1,...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "      <td>135.395763</td>\n",
       "      <td>129.373778</td>\n",
       "      <td>-10.494216</td>\n",
       "      <td>[AAPL_Close_ma3, SRVPRD_lag1, AAPL_Close_lag1,...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1</td>\n",
       "      <td>60.468072</td>\n",
       "      <td>55.942654</td>\n",
       "      <td>-2.348495</td>\n",
       "      <td>[ICSA_lag6, SP500_lag1, SP500, SP500_lag3, AMZ...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>3</td>\n",
       "      <td>125.399820</td>\n",
       "      <td>120.908018</td>\n",
       "      <td>-13.400953</td>\n",
       "      <td>[ICSA_lag6, SP500_lag1, SP500, SP500_lag3, AMZ...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1</td>\n",
       "      <td>37.567129</td>\n",
       "      <td>33.386094</td>\n",
       "      <td>-0.851867</td>\n",
       "      <td>[GOOG_Close_ma3, BUSINV_lag3, CSUSHPINSA, CSUS...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>3</td>\n",
       "      <td>106.920773</td>\n",
       "      <td>103.295563</td>\n",
       "      <td>-14.000921</td>\n",
       "      <td>[GOOG_Close_ma3, BUSINV_lag3, CSUSHPINSA, CSUS...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>27.034320</td>\n",
       "      <td>23.022412</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>[GOOGL_Close_ma3, BUSINV_lag3, RSXFS_lag3, GOO...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>3</td>\n",
       "      <td>105.296266</td>\n",
       "      <td>101.687676</td>\n",
       "      <td>-13.843321</td>\n",
       "      <td>[GOOGL_Close_ma3, BUSINV_lag3, RSXFS_lag3, GOO...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>META</td>\n",
       "      <td>1</td>\n",
       "      <td>142.660243</td>\n",
       "      <td>117.014070</td>\n",
       "      <td>0.310590</td>\n",
       "      <td>[META_Close_ma3, MORTGAGE30US_lag1, UNRATE_lag...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>META</td>\n",
       "      <td>3</td>\n",
       "      <td>502.119306</td>\n",
       "      <td>474.065796</td>\n",
       "      <td>-8.205979</td>\n",
       "      <td>[META_Close_ma3, MORTGAGE30US_lag1, UNRATE_lag...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>1</td>\n",
       "      <td>61.279385</td>\n",
       "      <td>47.524341</td>\n",
       "      <td>0.037331</td>\n",
       "      <td>[BOPGSTB, CPIAUCSL, TSLA_Close_lag3, BOPGSTB_l...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>3</td>\n",
       "      <td>258.707029</td>\n",
       "      <td>251.055029</td>\n",
       "      <td>-16.157917</td>\n",
       "      <td>[BOPGSTB, CPIAUCSL, TSLA_Close_lag3, BOPGSTB_l...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>1</td>\n",
       "      <td>36.712397</td>\n",
       "      <td>26.937945</td>\n",
       "      <td>0.602849</td>\n",
       "      <td>[AVGO_Close_lag1, SP500_lag3, AVGO_Close_ma3, ...</td>\n",
       "      <td>Date    Actual   Predicted  C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>3</td>\n",
       "      <td>103.383640</td>\n",
       "      <td>85.411568</td>\n",
       "      <td>-2.149446</td>\n",
       "      <td>[AVGO_Close_lag1, SP500_lag3, AVGO_Close_ma3, ...</td>\n",
       "      <td>Date    Actual  Predicted  Cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker  horizon        rmse         mae         r2  \\\n",
       "0    NVDA        1   23.682996   15.688522   0.693331   \n",
       "1    NVDA        3   60.131066   42.047603  -0.976946   \n",
       "2    MSFT        1   38.066642   31.475942   0.761796   \n",
       "3    MSFT        3  284.814116  273.926725 -12.334717   \n",
       "4    AAPL        1   26.516358   22.643422   0.559144   \n",
       "5    AAPL        3  135.395763  129.373778 -10.494216   \n",
       "6    AMZN        1   60.468072   55.942654  -2.348495   \n",
       "7    AMZN        3  125.399820  120.908018 -13.400953   \n",
       "8    GOOG        1   37.567129   33.386094  -0.851867   \n",
       "9    GOOG        3  106.920773  103.295563 -14.000921   \n",
       "10  GOOGL        1   27.034320   23.022412   0.021556   \n",
       "11  GOOGL        3  105.296266  101.687676 -13.843321   \n",
       "12   META        1  142.660243  117.014070   0.310590   \n",
       "13   META        3  502.119306  474.065796  -8.205979   \n",
       "14   TSLA        1   61.279385   47.524341   0.037331   \n",
       "15   TSLA        3  258.707029  251.055029 -16.157917   \n",
       "16   AVGO        1   36.712397   26.937945   0.602849   \n",
       "17   AVGO        3  103.383640   85.411568  -2.149446   \n",
       "\n",
       "                                         top_features  \\\n",
       "0   [SP500_lag3, NVDA_Close_ma3, PAYEMS_lag1, RSXF...   \n",
       "1   [SP500_lag3, NVDA_Close_ma3, PAYEMS_lag1, RSXF...   \n",
       "2   [CSUSHPINSA_lag6, CSUSHPINSA_lag3, CSUSHPINSA_...   \n",
       "3   [CSUSHPINSA_lag6, CSUSHPINSA_lag3, CSUSHPINSA_...   \n",
       "4   [AAPL_Close_ma3, SRVPRD_lag1, AAPL_Close_lag1,...   \n",
       "5   [AAPL_Close_ma3, SRVPRD_lag1, AAPL_Close_lag1,...   \n",
       "6   [ICSA_lag6, SP500_lag1, SP500, SP500_lag3, AMZ...   \n",
       "7   [ICSA_lag6, SP500_lag1, SP500, SP500_lag3, AMZ...   \n",
       "8   [GOOG_Close_ma3, BUSINV_lag3, CSUSHPINSA, CSUS...   \n",
       "9   [GOOG_Close_ma3, BUSINV_lag3, CSUSHPINSA, CSUS...   \n",
       "10  [GOOGL_Close_ma3, BUSINV_lag3, RSXFS_lag3, GOO...   \n",
       "11  [GOOGL_Close_ma3, BUSINV_lag3, RSXFS_lag3, GOO...   \n",
       "12  [META_Close_ma3, MORTGAGE30US_lag1, UNRATE_lag...   \n",
       "13  [META_Close_ma3, MORTGAGE30US_lag1, UNRATE_lag...   \n",
       "14  [BOPGSTB, CPIAUCSL, TSLA_Close_lag3, BOPGSTB_l...   \n",
       "15  [BOPGSTB, CPIAUCSL, TSLA_Close_lag3, BOPGSTB_l...   \n",
       "16  [AVGO_Close_lag1, SP500_lag3, AVGO_Close_ma3, ...   \n",
       "17  [AVGO_Close_lag1, SP500_lag3, AVGO_Close_ma3, ...   \n",
       "\n",
       "                                          backtest_df  \n",
       "0                    Date    Actual  Predicted  Cu...  \n",
       "1                    Date    Actual  Predicted  Cu...  \n",
       "2                    Date    Actual   Predicted  C...  \n",
       "3                    Date    Actual  Predicted  Cu...  \n",
       "4                    Date    Actual   Predicted  C...  \n",
       "5                    Date    Actual  Predicted  Cu...  \n",
       "6                    Date    Actual   Predicted  C...  \n",
       "7                    Date    Actual  Predicted  Cu...  \n",
       "8                    Date    Actual   Predicted  C...  \n",
       "9                    Date    Actual  Predicted  Cu...  \n",
       "10                   Date    Actual   Predicted  C...  \n",
       "11                   Date    Actual  Predicted  Cu...  \n",
       "12                   Date    Actual   Predicted  C...  \n",
       "13                   Date    Actual  Predicted  Cu...  \n",
       "14                   Date    Actual   Predicted  C...  \n",
       "15                   Date    Actual  Predicted  Cu...  \n",
       "16                   Date    Actual   Predicted  C...  \n",
       "17                   Date    Actual  Predicted  Cu...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478b381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
